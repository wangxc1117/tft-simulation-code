{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327aa37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded spatial_utils from: /home/wangxc1117/geospatial-neural-adapter/geospatial_neural_adapter/cpp_extensions/spatial_utils.so\n",
      "Device: cuda\n",
      "Weather2K: (1866, 13, 13632)\n",
      "Beijing stations: 31\n",
      "Using past covariates: ['ap', 'mxt', 'mnt', 'rh', 'p3', 'wd_sin', 'wd_cos', 'ws', 'mwd_sin', 'mwd_cos', 'mws']\n",
      "Y: (13632, 31) | Xfull: (13632, 31, 12) | p_dim: 12\n",
      "\n",
      "=== After scaling ===\n",
      "X_s: (13632, 31, 12) | y_s: (13632, 31)\n",
      "X_s finite: True | y_s finite: True\n",
      "\n",
      "=== Feature variance screening (TRAIN ONLY, pooled) ===\n",
      "  [00] lag1         std=9.999539852142e-01\n",
      "  [01] ap           std=9.999643564224e-01\n",
      "  [02] mxt          std=1.000031113625e+00\n",
      "  [03] mnt          std=9.999288916588e-01\n",
      "  [04] rh           std=9.999594688416e-01\n",
      "  [05] p3           std=9.997370839119e-01\n",
      "  [06] wd_sin       std=9.999293088913e-01\n",
      "  [07] wd_cos       std=1.000008702278e+00\n",
      "  [08] ws           std=1.000204324722e+00\n",
      "  [09] mwd_sin      std=9.999343752861e-01\n",
      "  [10] mwd_cos      std=9.999788999557e-01\n",
      "  [11] mws          std=1.000123739243e+00\n",
      "Dropped: NONE\n",
      "X_s_red: (13632, 31, 12) | p_red: 12\n",
      "kept features: ['lag1', 'ap', 'mxt', 'mnt', 'rh', 'p3', 'wd_sin', 'wd_cos', 'ws', 'mwd_sin', 'mwd_cos', 'mws']\n",
      "\n",
      "=== OLS fitted ===\n",
      "b0: -4.009460496945394e-08\n",
      "beta shape: (12,)\n",
      "\n",
      "=== Rolling non-overlap (POOLED, TEST) [OLS recursive | FAIR vs TFT] ===\n",
      "windows=85 | step=24 | each window predicts H=24 | stations=31\n",
      "RMSE: 0.6000756025314331\n",
      "MAE : 0.47446948289871216\n",
      "\n",
      "=== P50 q-risk (ROLLING, TEST) ===\n",
      "scaled  : 0.5436112982810826\n",
      "unscaled: 0.38202006751174183\n",
      "\n",
      "=== Plotting ALL 31 stations (2 figs per station) ===\n",
      "Saved FIG1 to: /home/wangxc1117/TFTModel-use/geospatial-neural-adapter-dev/examples/try/weather2k/OLS/OLS_plots_weather2k_beijing_pooled_fair_vs_tft_ALL_wd_sincos/FIG1_first_window\n",
      "Saved FIG2 to: /home/wangxc1117/TFTModel-use/geospatial-neural-adapter-dev/examples/try/weather2k/OLS/OLS_plots_weather2k_beijing_pooled_fair_vs_tft_ALL_wd_sincos/FIG2_full_test_stitched\n",
      "All done.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from geospatial_neural_adapter.data.preprocessing import prepare_all_with_scaling\n",
    "\n",
    "\n",
    "# Paths & settings\n",
    "W2K_PATH = Path(\"/home/wangxc1117/Weather2K/weather2k.npy\")\n",
    "\n",
    "GLOBAL_SEED = 42\n",
    "np.random.seed(GLOBAL_SEED)\n",
    "torch.manual_seed(GLOBAL_SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "train_ratio = 0.70\n",
    "val_ratio = 0.15\n",
    "L, H = 56, 24\n",
    "STEP = H\n",
    "EPS_STD = 1e-8\n",
    "\n",
    "PLOTS_DIR = Path(\"OLS_plots_weather2k_beijing_pooled_fair_vs_tft_ALL_wd_sincos\")\n",
    "FIG1_DIR = PLOTS_DIR / \"FIG1_first_window\"\n",
    "FIG2_DIR = PLOTS_DIR / \"FIG2_full_test_stitched\"\n",
    "FIG1_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG2_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "USE_MXT_MNT = True\n",
    "\n",
    "\n",
    "# Load data\n",
    "if not W2K_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Weather2K npy not found at: {W2K_PATH}\")\n",
    "\n",
    "arr = np.load(W2K_PATH, allow_pickle=False).astype(np.float32)\n",
    "S, V, T = arr.shape\n",
    "assert V == 13\n",
    "print(\"Weather2K:\", arr.shape)\n",
    "\n",
    "time_index = pd.date_range(\"2000-01-01\", periods=T, freq=\"3H\")\n",
    "\n",
    "TARGET_IDX = 4\n",
    "IDX_AP  = 3\n",
    "IDX_MXT = 5\n",
    "IDX_MNT = 6\n",
    "IDX_RH  = 7\n",
    "IDX_P3  = 8\n",
    "IDX_WD  = 9\n",
    "IDX_WS  = 10\n",
    "IDX_MWD = 11\n",
    "IDX_MWS = 12\n",
    "\n",
    "LAT_MIN, LAT_MAX = 39.4, 41.1\n",
    "LON_MIN, LON_MAX = 115.4, 117.5\n",
    "lat = arr[:, 0, 0]\n",
    "lon = arr[:, 1, 0]\n",
    "use_idx = np.where(\n",
    "    (lat >= LAT_MIN) & (lat <= LAT_MAX) &\n",
    "    (lon >= LON_MIN) & (lon <= LON_MAX)\n",
    ")[0]\n",
    "N = len(use_idx)\n",
    "print(\"Beijing stations:\", N)\n",
    "if N == 0:\n",
    "    raise RuntimeError(\"No Beijing stations found. Check bounding box.\")\n",
    "\n",
    "\n",
    "# Build pooled arrays\n",
    "Y = np.stack([arr[s, TARGET_IDX] for s in use_idx], axis=1).astype(np.float32)\n",
    "\n",
    "ap  = np.stack([arr[s, IDX_AP]  for s in use_idx], axis=1).astype(np.float32)\n",
    "rh  = np.stack([arr[s, IDX_RH]  for s in use_idx], axis=1).astype(np.float32)\n",
    "p3  = np.stack([arr[s, IDX_P3]  for s in use_idx], axis=1).astype(np.float32)\n",
    "ws  = np.stack([arr[s, IDX_WS]  for s in use_idx], axis=1).astype(np.float32)\n",
    "mws = np.stack([arr[s, IDX_MWS] for s in use_idx], axis=1).astype(np.float32)\n",
    "\n",
    "mxt = np.stack([arr[s, IDX_MXT] for s in use_idx], axis=1).astype(np.float32)\n",
    "mnt = np.stack([arr[s, IDX_MNT] for s in use_idx], axis=1).astype(np.float32)\n",
    "\n",
    "wd_deg  = np.stack([arr[s, IDX_WD]  for s in use_idx], axis=1).astype(np.float32)\n",
    "mwd_deg = np.stack([arr[s, IDX_MWD] for s in use_idx], axis=1).astype(np.float32)\n",
    "\n",
    "wd_rad  = (wd_deg.astype(np.float64)  * np.pi / 180.0)\n",
    "mwd_rad = (mwd_deg.astype(np.float64) * np.pi / 180.0)\n",
    "\n",
    "wd_sin  = np.sin(wd_rad).astype(np.float32)\n",
    "wd_cos  = np.cos(wd_rad).astype(np.float32)\n",
    "mwd_sin = np.sin(mwd_rad).astype(np.float32)\n",
    "mwd_cos = np.cos(mwd_rad).astype(np.float32)\n",
    "\n",
    "cov_blocks: List[np.ndarray] = [ap]\n",
    "cov_names: List[str] = [\"ap\"]\n",
    "\n",
    "if USE_MXT_MNT:\n",
    "    cov_blocks += [mxt, mnt]\n",
    "    cov_names  += [\"mxt\", \"mnt\"]\n",
    "\n",
    "cov_blocks += [rh, p3, wd_sin, wd_cos, ws, mwd_sin, mwd_cos, mws]\n",
    "cov_names  += [\"rh\", \"p3\", \"wd_sin\", \"wd_cos\", \"ws\", \"mwd_sin\", \"mwd_cos\", \"mws\"]\n",
    "\n",
    "Xcov = np.stack(cov_blocks, axis=2).astype(np.float32)\n",
    "\n",
    "print(\"Using past covariates:\", cov_names)\n",
    "\n",
    "lag1 = np.zeros((T, N, 1), dtype=np.float32)\n",
    "lag1[1:, :, 0] = Y[:-1, :]\n",
    "\n",
    "Xfull = np.concatenate([lag1, Xcov], axis=2).astype(np.float32)\n",
    "feat_names_full = [\"lag1\"] + cov_names\n",
    "p_dim = Xfull.shape[2]\n",
    "print(\"Y:\", Y.shape, \"| Xfull:\", Xfull.shape, \"| p_dim:\", p_dim)\n",
    "\n",
    "cat_dummy = np.zeros((T, N, 1), dtype=np.int64)\n",
    "\n",
    "\n",
    "# Pooled train-only scaling\n",
    "train_ds, val_ds, test_ds, preprocessor = prepare_all_with_scaling(\n",
    "    cat_features=cat_dummy,\n",
    "    cont_features=Xfull,\n",
    "    targets=Y,\n",
    "    train_ratio=train_ratio,\n",
    "    val_ratio=val_ratio,\n",
    "    feature_scaler_type=\"standard\",\n",
    "    target_scaler_type=\"standard\",\n",
    "    fit_on_train_only=True,\n",
    ")\n",
    "\n",
    "def stitch_from_dsets(dsets) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    Xs = np.concatenate([ds.tensors[1].cpu().numpy().astype(np.float32) for ds in dsets], axis=0)\n",
    "    Ys = np.concatenate([ds.tensors[2].cpu().numpy().astype(np.float32) for ds in dsets], axis=0)\n",
    "    return Xs, Ys\n",
    "\n",
    "X_s, y_s = stitch_from_dsets([train_ds, val_ds, test_ds])\n",
    "assert X_s.shape == Xfull.shape\n",
    "assert y_s.shape == Y.shape\n",
    "\n",
    "print(\"\\n=== After scaling ===\")\n",
    "print(\"X_s:\", X_s.shape, \"| y_s:\", y_s.shape)\n",
    "print(\"X_s finite:\", bool(np.isfinite(X_s).all()), \"| y_s finite:\", bool(np.isfinite(y_s).all()))\n",
    "if not np.isfinite(X_s).all() or not np.isfinite(y_s).all():\n",
    "    raise ValueError(\"Non-finite values after scaling.\")\n",
    "\n",
    "cut_train = int(T * train_ratio)\n",
    "cut_val = int(T * (train_ratio + val_ratio))\n",
    "train_len = cut_train\n",
    "test_start = cut_val\n",
    "\n",
    "\n",
    "# Drop near-constant features based on TRAIN ONLY (pooled)\n",
    "X_train = X_s[:train_len]\n",
    "X_flat = X_train.reshape(-1, p_dim)\n",
    "feat_std = X_flat.std(axis=0)\n",
    "\n",
    "keep_mask = feat_std > EPS_STD\n",
    "kept_idx = np.where(keep_mask)[0].tolist()\n",
    "dropped_idx = np.where(~keep_mask)[0].tolist()\n",
    "\n",
    "print(\"\\n=== Feature variance screening (TRAIN ONLY, pooled) ===\")\n",
    "for i, nm in enumerate(feat_names_full):\n",
    "    print(f\"  [{i:02d}] {nm:12s} std={feat_std[i]:.12e}\")\n",
    "print(\"Dropped:\", [feat_names_full[i] for i in dropped_idx] if dropped_idx else \"NONE\")\n",
    "\n",
    "if len(kept_idx) == 0:\n",
    "    raise ValueError(\"All features dropped; cannot fit OLS.\")\n",
    "\n",
    "X_s_red = X_s[:, :, keep_mask].astype(np.float32)\n",
    "feat_names_red = [feat_names_full[i] for i in kept_idx]\n",
    "p_red = X_s_red.shape[2]\n",
    "print(\"X_s_red:\", X_s_red.shape, \"| p_red:\", p_red)\n",
    "print(\"kept features:\", feat_names_red)\n",
    "\n",
    "if \"lag1\" not in feat_names_red:\n",
    "    raise ValueError(\"lag1 was dropped, which should not happen.\")\n",
    "\n",
    "\n",
    "# OLS fit (pooled) on TRAIN\n",
    "Xtr = X_s_red[:train_len].reshape(-1, p_red)\n",
    "ytr = y_s[:train_len].reshape(-1, 1)\n",
    "\n",
    "Xtr_t = torch.from_numpy(Xtr).to(DEVICE)\n",
    "ytr_t = torch.from_numpy(ytr).to(DEVICE)\n",
    "\n",
    "ones = torch.ones((Xtr_t.shape[0], 1), device=DEVICE, dtype=Xtr_t.dtype)\n",
    "X_aug = torch.cat([ones, Xtr_t], dim=1)\n",
    "\n",
    "beta_aug = torch.linalg.lstsq(X_aug, ytr_t).solution.squeeze(1)\n",
    "b0 = float(beta_aug[0].detach().cpu().item())\n",
    "beta = beta_aug[1:].detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "print(\"\\n=== OLS fitted ===\")\n",
    "print(\"b0:\", b0)\n",
    "print(\"beta shape:\", beta.shape)\n",
    "\n",
    "\n",
    "# Rolling non-overlap on TEST (FAIR vs TFT)\n",
    "def qrisk(y_true, y_pred, q=0.5, eps=1e-8):\n",
    "    y_true = np.asarray(y_true, dtype=np.float64)\n",
    "    y_pred = np.asarray(y_pred, dtype=np.float64)\n",
    "    e = y_true - y_pred\n",
    "    return float(2.0 * np.sum(np.maximum(q * e, (q - 1) * e)) / (np.sum(np.abs(y_true)) + eps))\n",
    "\n",
    "IDX_LAG1_RED = feat_names_red.index(\"lag1\")\n",
    "\n",
    "def rolling_ols_recursive_nonoverlap_fair(\n",
    "    X_s_red_full: np.ndarray,\n",
    "    y_s_full: np.ndarray,\n",
    "    start_ctx: int,\n",
    "    end_T: int,\n",
    "    H: int,\n",
    "    step: int,\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    t0_list = list(range(start_ctx, end_T - H + 1, step))\n",
    "    yh_all, yt_all, kept_t0 = [], [], []\n",
    "\n",
    "    for t0 in t0_list:\n",
    "        if t0 < 1:\n",
    "            continue\n",
    "\n",
    "        freeze_cov = X_s_red_full[t0 - 1].copy().astype(np.float32)\n",
    "        ytru = y_s_full[t0:t0+H].astype(np.float32)\n",
    "\n",
    "        prev = y_s_full[t0 - 1].astype(np.float32)\n",
    "        yhat = np.empty((H, N), dtype=np.float32)\n",
    "\n",
    "        for k in range(H):\n",
    "            Xt = freeze_cov.copy()\n",
    "            Xt[:, IDX_LAG1_RED] = prev\n",
    "            ypred = Xt @ beta.reshape(-1, 1)\n",
    "            ypred = ypred.reshape(-1) + b0\n",
    "            yhat[k] = ypred.astype(np.float32)\n",
    "            prev = ypred.astype(np.float32)\n",
    "\n",
    "        yh_all.append(yhat)\n",
    "        yt_all.append(ytru)\n",
    "        kept_t0.append(t0)\n",
    "\n",
    "    if len(yh_all) == 0:\n",
    "        raise RuntimeError(\"No rolling windows produced. Check start/end/H/step.\")\n",
    "\n",
    "    return np.stack(yh_all, axis=0), np.stack(yt_all, axis=0), np.asarray(kept_t0, dtype=int)\n",
    "\n",
    "start_ctx = max(test_start, L)\n",
    "yhat_roll, ytrue_roll, t0_list = rolling_ols_recursive_nonoverlap_fair(\n",
    "    X_s_red_full=X_s_red,\n",
    "    y_s_full=y_s,\n",
    "    start_ctx=start_ctx,\n",
    "    end_T=T,\n",
    "    H=H,\n",
    "    step=STEP,\n",
    ")\n",
    "\n",
    "W = yhat_roll.shape[0]\n",
    "diff = yhat_roll - ytrue_roll\n",
    "rmse = float(np.sqrt(np.mean(diff ** 2)))\n",
    "mae = float(np.mean(np.abs(diff)))\n",
    "\n",
    "print(\"\\n=== Rolling non-overlap (POOLED, TEST) [OLS recursive | FAIR vs TFT] ===\")\n",
    "print(f\"windows={W} | step={STEP} | each window predicts H={H} | stations={N}\")\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAE :\", mae)\n",
    "\n",
    "yhat_f = yhat_roll.reshape(-1, N)\n",
    "ytrue_f = ytrue_roll.reshape(-1, N)\n",
    "\n",
    "qr_scaled = qrisk(ytrue_f, yhat_f, q=0.5)\n",
    "ytrue_un = preprocessor.inverse_transform_targets(ytrue_f)\n",
    "yhat_un = preprocessor.inverse_transform_targets(yhat_f)\n",
    "qr_unscaled = qrisk(ytrue_un, yhat_un, q=0.5)\n",
    "\n",
    "print(\"\\n=== P50 q-risk (ROLLING, TEST) ===\")\n",
    "print(\"scaled  :\", qr_scaled)\n",
    "print(\"unscaled:\", qr_unscaled)\n",
    "\n",
    "\n",
    "# Plots: FIG1 first window (H steps), FIG2 full TEST stitched\n",
    "t_start = int(t0_list[0])\n",
    "t_end_excl = int(t0_list[0] + W * H)\n",
    "times_fig2 = time_index[t_start:t_end_excl]\n",
    "if len(times_fig2) != W * H:\n",
    "    raise RuntimeError(\"Time axis length mismatch for stitched TEST plot.\")\n",
    "\n",
    "ytrue_stitched = ytrue_roll.reshape(W * H, N)\n",
    "yhat_stitched = yhat_roll.reshape(W * H, N)\n",
    "\n",
    "print(f\"\\n=== Plotting ALL {N} stations (2 figs per station) ===\")\n",
    "for j in range(N):\n",
    "    station_id = int(use_idx[j])\n",
    "\n",
    "    ytrue_fig1 = ytrue_roll[0, :, j]\n",
    "    yhat_fig1 = yhat_roll[0, :, j]\n",
    "\n",
    "    plt.figure(figsize=(9, 4), dpi=140)\n",
    "    plt.plot(range(H), ytrue_fig1, \"-o\", linewidth=2, markersize=3, label=\"True (scaled)\")\n",
    "    plt.plot(range(H), yhat_fig1, \"-o\", linewidth=2, markersize=3, label=\"Pred (scaled)\")\n",
    "    plt.title(f\"FIG1 OLS FAIR | Beijing st_{station_id} | first window | H={H} (scaled)\")\n",
    "    plt.xlabel(\"3-hour step within window\")\n",
    "    plt.ylabel(\"Scaled t\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIG1_DIR / f\"FIG1_OLS_fair_firstWindow_st{station_id}_H{H}_scaled.png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(12, 4), dpi=140)\n",
    "    plt.plot(times_fig2, ytrue_stitched[:, j], \"-\", linewidth=2, label=\"True (scaled)\")\n",
    "    plt.plot(times_fig2, yhat_stitched[:, j], \"-\", linewidth=2, label=\"Pred (scaled)\")\n",
    "    plt.title(f\"FIG2 OLS FAIR | Beijing st_{station_id} | full TEST (stitched) | H={H} (scaled)\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Scaled t\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIG2_DIR / f\"FIG2_OLS_fair_testAll_st{station_id}_H{H}_scaled.png\")\n",
    "    plt.close()\n",
    "\n",
    "print(f\"Saved FIG1 to: {FIG1_DIR.resolve()}\")\n",
    "print(f\"Saved FIG2 to: {FIG2_DIR.resolve()}\")\n",
    "print(\"All done.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial-neural-adapter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
