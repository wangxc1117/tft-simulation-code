{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327aa37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded spatial_utils from: /home/wangxc1117/geospatial-neural-adapter/geospatial_neural_adapter/cpp_extensions/spatial_utils.so\n",
      "PLOTS_DIR: /home/wangxc1117/TFTModel-use/geospatial-neural-adapter-dev/examples/try/weather2k/VAR/VARX_plots_weather2k_beijing_pooled_freezeCov_wdSinCos_P1_H24\n",
      "Weather2K: (1866, 13, 13632)\n",
      "Beijing stations: 31\n",
      "Y_raw: (13632, 31) | Xcov_raw: (13632, 31, 11) | K: 11\n",
      "Past covs: ['ap', 'mxt', 'mnt', 'rh', 'p3', 'wd_sin', 'wd_cos', 'ws', 'mwd_sin', 'mwd_cos', 'mws']\n",
      "\n",
      "=== After scaling ===\n",
      "Xcov_s: (13632, 31, 11) | y_s: (13632, 31)\n",
      "Xcov_s finite: True | y_s finite: True\n",
      "\n",
      "=== Split (by time index) ===\n",
      "Train: 0 -> 9541 | len = 9542\n",
      "Val  : 9542 -> 11586 | len = 2045\n",
      "Test : 11587 -> 13631 | len = 2045\n",
      "\n",
      "=== VARX train design ===\n",
      "Xtr: (9541, 373) | Ytr: (9541, 31) | N: 31 | P: 1 | K: 11\n",
      "D = 373  (= 1 + N*P + N*K )\n",
      "\n",
      "=== VARX fitted (train-only) ===\n",
      "B: (373, 31) | rank: 373\n",
      "B finite: True\n",
      "\n",
      "=== Rolling non-overlap (POOLED, TEST) [VARX + FREEZE cov | FAIR vs TFT] ===\n",
      "windows=85 | step=24 | each window predicts H=24 | stations=31 | P=1 | K=11\n",
      "RMSE: 0.5939228534698486\n",
      "MAE : 0.4689213037490845\n",
      "\n",
      "=== P50 q-risk (ROLLING, TEST) ===\n",
      "scaled  : 0.5372546419025567\n",
      "unscaled: 0.37755296013527656\n",
      "\n",
      "=== Plotting ALL stations (2 figs/station) ===\n",
      "Saved plots to: /home/wangxc1117/TFTModel-use/geospatial-neural-adapter-dev/examples/try/weather2k/VAR/VARX_plots_weather2k_beijing_pooled_freezeCov_wdSinCos_P1_H24\n",
      "All done.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from geospatial_neural_adapter.data.preprocessing import prepare_all_with_scaling\n",
    "\n",
    "\n",
    "# Paths & settings\n",
    "W2K_PATH = Path(\"/home/wangxc1117/Weather2K/weather2k.npy\")\n",
    "\n",
    "GLOBAL_SEED = 42\n",
    "np.random.seed(GLOBAL_SEED)\n",
    "\n",
    "train_ratio = 0.70\n",
    "val_ratio = 0.15\n",
    "\n",
    "L = 56\n",
    "H = 24\n",
    "STEP = H\n",
    "\n",
    "P = 1\n",
    "\n",
    "LAT_MIN, LAT_MAX = 39.4, 41.1\n",
    "LON_MIN, LON_MAX = 115.4, 117.5\n",
    "\n",
    "EXP_ROOT = Path.cwd()\n",
    "PLOTS_DIR = (EXP_ROOT / f\"VARX_plots_weather2k_beijing_pooled_freezeCov_wdSinCos_P{P}_H{H}\").resolve()\n",
    "PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"PLOTS_DIR:\", PLOTS_DIR)\n",
    "\n",
    "\n",
    "# Load data\n",
    "if not W2K_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Weather2K npy not found at: {W2K_PATH}\")\n",
    "\n",
    "arr = np.load(W2K_PATH, allow_pickle=False).astype(np.float32)\n",
    "S, V, T = arr.shape\n",
    "if V != 13:\n",
    "    raise ValueError(f\"Expected 13 variables, got {V}\")\n",
    "\n",
    "print(\"Weather2K:\", arr.shape)\n",
    "time_index = pd.date_range(\"2000-01-01\", periods=T, freq=\"3H\")\n",
    "\n",
    "TARGET_IDX = 4\n",
    "\n",
    "IDX_AP  = 3\n",
    "IDX_MXT = 5\n",
    "IDX_MNT = 6\n",
    "IDX_RH  = 7\n",
    "IDX_P3  = 8\n",
    "IDX_WD  = 9\n",
    "IDX_WS  = 10\n",
    "IDX_MWD = 11\n",
    "IDX_MWS = 12\n",
    "\n",
    "lat = arr[:, 0, 0]\n",
    "lon = arr[:, 1, 0]\n",
    "use_idx = np.where(\n",
    "    (lat >= LAT_MIN) & (lat <= LAT_MAX) &\n",
    "    (lon >= LON_MIN) & (lon <= LON_MAX)\n",
    ")[0]\n",
    "N = len(use_idx)\n",
    "\n",
    "print(\"Beijing stations:\", N)\n",
    "if N == 0:\n",
    "    raise RuntimeError(\"No Beijing stations found. Check bounding box.\")\n",
    "\n",
    "\n",
    "# Build pooled raw arrays\n",
    "Y_raw = np.stack([arr[s, TARGET_IDX, :] for s in use_idx], axis=1).astype(np.float32)\n",
    "\n",
    "ap  = np.stack([arr[s, IDX_AP,  :] for s in use_idx], axis=1).astype(np.float32)\n",
    "mxt = np.stack([arr[s, IDX_MXT, :] for s in use_idx], axis=1).astype(np.float32)\n",
    "mnt = np.stack([arr[s, IDX_MNT, :] for s in use_idx], axis=1).astype(np.float32)\n",
    "rh  = np.stack([arr[s, IDX_RH,  :] for s in use_idx], axis=1).astype(np.float32)\n",
    "p3  = np.stack([arr[s, IDX_P3,  :] for s in use_idx], axis=1).astype(np.float32)\n",
    "ws  = np.stack([arr[s, IDX_WS,  :] for s in use_idx], axis=1).astype(np.float32)\n",
    "mws = np.stack([arr[s, IDX_MWS, :] for s in use_idx], axis=1).astype(np.float32)\n",
    "\n",
    "wd_deg  = np.stack([arr[s, IDX_WD,  :] for s in use_idx], axis=1).astype(np.float32)\n",
    "mwd_deg = np.stack([arr[s, IDX_MWD, :] for s in use_idx], axis=1).astype(np.float32)\n",
    "\n",
    "wd_rad  = (wd_deg.astype(np.float64)  * np.pi / 180.0)\n",
    "mwd_rad = (mwd_deg.astype(np.float64) * np.pi / 180.0)\n",
    "\n",
    "wd_sin  = np.sin(wd_rad).astype(np.float32)\n",
    "wd_cos  = np.cos(wd_rad).astype(np.float32)\n",
    "mwd_sin = np.sin(mwd_rad).astype(np.float32)\n",
    "mwd_cos = np.cos(mwd_rad).astype(np.float32)\n",
    "\n",
    "PAST_COV_COLS = [\"ap\", \"mxt\", \"mnt\", \"rh\", \"p3\", \"wd_sin\", \"wd_cos\", \"ws\", \"mwd_sin\", \"mwd_cos\", \"mws\"]\n",
    "Xcov_raw = np.stack(\n",
    "    [ap, mxt, mnt, rh, p3, wd_sin, wd_cos, ws, mwd_sin, mwd_cos, mws],\n",
    "    axis=2\n",
    ").astype(np.float32)\n",
    "\n",
    "K = Xcov_raw.shape[2]\n",
    "print(\"Y_raw:\", Y_raw.shape, \"| Xcov_raw:\", Xcov_raw.shape, \"| K:\", K)\n",
    "print(\"Past covs:\", PAST_COV_COLS)\n",
    "\n",
    "cat_dummy = np.zeros((T, N, 1), dtype=np.int64)\n",
    "\n",
    "\n",
    "# POOLED train-only scaling\n",
    "train_ds, val_ds, test_ds, preprocessor = prepare_all_with_scaling(\n",
    "    cat_features=cat_dummy,\n",
    "    cont_features=Xcov_raw,\n",
    "    targets=Y_raw,\n",
    "    train_ratio=train_ratio,\n",
    "    val_ratio=val_ratio,\n",
    "    feature_scaler_type=\"standard\",\n",
    "    target_scaler_type=\"standard\",\n",
    "    fit_on_train_only=True,\n",
    ")\n",
    "\n",
    "def stitch_scaled(dsets) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    Xs = np.concatenate([ds.tensors[1].cpu().numpy().astype(np.float32) for ds in dsets], axis=0)\n",
    "    Ys = np.concatenate([ds.tensors[2].cpu().numpy().astype(np.float32) for ds in dsets], axis=0)\n",
    "    return Xs, Ys\n",
    "\n",
    "Xcov_s, y_s = stitch_scaled([train_ds, val_ds, test_ds])\n",
    "if Xcov_s.shape != Xcov_raw.shape or y_s.shape != Y_raw.shape:\n",
    "    raise ValueError(\"Scaled arrays shape mismatch. Check prepare_all_with_scaling output.\")\n",
    "\n",
    "print(\"\\n=== After scaling ===\")\n",
    "print(\"Xcov_s:\", Xcov_s.shape, \"| y_s:\", y_s.shape)\n",
    "print(\"Xcov_s finite:\", bool(np.isfinite(Xcov_s).all()), \"| y_s finite:\", bool(np.isfinite(y_s).all()))\n",
    "if (not np.isfinite(Xcov_s).all()) or (not np.isfinite(y_s).all()):\n",
    "    raise ValueError(\"Non-finite values after scaling.\")\n",
    "\n",
    "\n",
    "# Time splits\n",
    "cut_train = int(T * train_ratio)\n",
    "cut_val = int(T * (train_ratio + val_ratio))\n",
    "if not (0 < cut_train < cut_val < T):\n",
    "    raise ValueError(\"Bad split indices.\")\n",
    "\n",
    "print(\"\\n=== Split (by time index) ===\")\n",
    "print(\"Train:\", 0, \"->\", cut_train - 1, \"| len =\", cut_train)\n",
    "print(\"Val  :\", cut_train, \"->\", cut_val - 1, \"| len =\", cut_val - cut_train)\n",
    "print(\"Test :\", cut_val, \"->\", T - 1, \"| len =\", T - cut_val)\n",
    "\n",
    "start_ctx = max(cut_val, L, P)\n",
    "\n",
    "\n",
    "def build_varx_design(y: np.ndarray, x: np.ndarray, t_start: int, t_end_excl: int, p: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    Ttot, Nloc = y.shape\n",
    "    _, Nloc2, Kloc = x.shape\n",
    "    if Nloc2 != Nloc:\n",
    "        raise ValueError(\"x and y station dimension mismatch.\")\n",
    "    if t_start < p:\n",
    "        raise ValueError(\"t_start must be >= p.\")\n",
    "\n",
    "    rows = []\n",
    "    ys = []\n",
    "    for t in range(t_start, t_end_excl):\n",
    "        lag_parts = []\n",
    "        for i in range(1, p + 1):\n",
    "            lag_parts.append(y[t - i, :].reshape(-1))\n",
    "        lag_vec = np.concatenate(lag_parts, axis=0)\n",
    "\n",
    "        x_vec = x[t, :, :].reshape(-1)\n",
    "        feat = np.concatenate(\n",
    "            [np.array([1.0], dtype=np.float32), lag_vec.astype(np.float32), x_vec.astype(np.float32)],\n",
    "            axis=0\n",
    "        )\n",
    "        rows.append(feat)\n",
    "        ys.append(y[t, :].astype(np.float32))\n",
    "\n",
    "    Xmat = np.stack(rows, axis=0).astype(np.float32)\n",
    "    Ymat = np.stack(ys, axis=0).astype(np.float32)\n",
    "    return Xmat, Ymat\n",
    "\n",
    "Xtr, Ytr = build_varx_design(\n",
    "    y=y_s,\n",
    "    x=Xcov_s,\n",
    "    t_start=P,\n",
    "    t_end_excl=cut_train,\n",
    "    p=P,\n",
    ")\n",
    "\n",
    "M, D = Xtr.shape\n",
    "print(\"\\n=== VARX train design ===\")\n",
    "print(\"Xtr:\", Xtr.shape, \"| Ytr:\", Ytr.shape, \"| N:\", N, \"| P:\", P, \"| K:\", K)\n",
    "print(\"D =\", D, \" (= 1 + N*P + N*K )\")\n",
    "\n",
    "Xtr64 = Xtr.astype(np.float64)\n",
    "Ytr64 = Ytr.astype(np.float64)\n",
    "\n",
    "B, residuals, rank, svals = np.linalg.lstsq(Xtr64, Ytr64, rcond=None)\n",
    "B = B.astype(np.float32)\n",
    "\n",
    "print(\"\\n=== VARX fitted (train-only) ===\")\n",
    "print(\"B:\", B.shape, \"| rank:\", rank)\n",
    "print(\"B finite:\", bool(np.isfinite(B).all()))\n",
    "if not np.isfinite(B).all():\n",
    "    raise ValueError(\"Non-finite coefficients in VARX fit. Check data/scaling.\")\n",
    "\n",
    "\n",
    "def qrisk(y_true: np.ndarray, y_pred: np.ndarray, q: float = 0.5, eps: float = 1e-8) -> float:\n",
    "    y_true = np.asarray(y_true, dtype=np.float64)\n",
    "    y_pred = np.asarray(y_pred, dtype=np.float64)\n",
    "    e = y_true - y_pred\n",
    "    return float(2.0 * np.sum(np.maximum(q * e, (q - 1.0) * e)) / (np.sum(np.abs(y_true)) + eps))\n",
    "\n",
    "def rolling_varx_freeze_nonoverlap(\n",
    "    y: np.ndarray,\n",
    "    x: np.ndarray,\n",
    "    B: np.ndarray,\n",
    "    start_ctx: int,\n",
    "    end_T: int,\n",
    "    p: int,\n",
    "    H: int,\n",
    "    step: int,\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    t0_list = list(range(start_ctx, end_T - H + 1, step))\n",
    "    yh_all: List[np.ndarray] = []\n",
    "    yt_all: List[np.ndarray] = []\n",
    "    kept_t0: List[int] = []\n",
    "\n",
    "    for t0 in t0_list:\n",
    "        if t0 < p:\n",
    "            continue\n",
    "\n",
    "        ytru = y[t0:t0 + H, :].astype(np.float32)\n",
    "\n",
    "        x_freeze = x[t0 - 1, :, :].reshape(-1).astype(np.float32)\n",
    "\n",
    "        hist = [y[t0 - i, :].astype(np.float32) for i in range(1, p + 1)]\n",
    "\n",
    "        yhat = np.empty((H, N), dtype=np.float32)\n",
    "\n",
    "        for k in range(H):\n",
    "            lag_vec = np.concatenate([hist[i].reshape(-1) for i in range(p)], axis=0).astype(np.float32)\n",
    "            feat = np.concatenate([np.array([1.0], dtype=np.float32), lag_vec, x_freeze], axis=0)\n",
    "            ypred = feat @ B\n",
    "            yhat[k, :] = ypred.astype(np.float32)\n",
    "            hist = [ypred.astype(np.float32)] + hist[:p - 1]\n",
    "\n",
    "        yh_all.append(yhat)\n",
    "        yt_all.append(ytru)\n",
    "        kept_t0.append(t0)\n",
    "\n",
    "    if len(yh_all) == 0:\n",
    "        raise RuntimeError(\"No rolling windows produced. Check start_ctx/end_T/H/step/p.\")\n",
    "\n",
    "    return np.stack(yh_all, axis=0), np.stack(yt_all, axis=0), np.asarray(kept_t0, dtype=int)\n",
    "\n",
    "yhat_roll, ytrue_roll, t0_list = rolling_varx_freeze_nonoverlap(\n",
    "    y=y_s,\n",
    "    x=Xcov_s,\n",
    "    B=B,\n",
    "    start_ctx=start_ctx,\n",
    "    end_T=T,\n",
    "    p=P,\n",
    "    H=H,\n",
    "    step=STEP,\n",
    ")\n",
    "\n",
    "W = yhat_roll.shape[0]\n",
    "diff = yhat_roll - ytrue_roll\n",
    "rmse = float(np.sqrt(np.mean(diff ** 2)))\n",
    "mae = float(np.mean(np.abs(diff)))\n",
    "\n",
    "print(\"\\n=== Rolling non-overlap (POOLED, TEST) [VARX + FREEZE cov | FAIR vs TFT] ===\")\n",
    "print(f\"windows={W} | step={STEP} | each window predicts H={H} | stations={N} | P={P} | K={K}\")\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAE :\", mae)\n",
    "\n",
    "yhat_f = yhat_roll.reshape(-1, N)\n",
    "ytrue_f = ytrue_roll.reshape(-1, N)\n",
    "\n",
    "qr_scaled = qrisk(ytrue_f, yhat_f, q=0.5)\n",
    "\n",
    "ytrue_un = preprocessor.inverse_transform_targets(ytrue_f)\n",
    "yhat_un = preprocessor.inverse_transform_targets(yhat_f)\n",
    "qr_unscaled = qrisk(ytrue_un, yhat_un, q=0.5)\n",
    "\n",
    "print(\"\\n=== P50 q-risk (ROLLING, TEST) ===\")\n",
    "print(\"scaled  :\", qr_scaled)\n",
    "print(\"unscaled:\", qr_unscaled)\n",
    "\n",
    "\n",
    "w0 = 0\n",
    "t_start = int(t0_list[0])\n",
    "t_end_excl = t_start + W * H\n",
    "times_fig2 = time_index[t_start:t_end_excl]\n",
    "\n",
    "ytrue_stitched = ytrue_roll.reshape(W * H, N)\n",
    "yhat_stitched = yhat_roll.reshape(W * H, N)\n",
    "\n",
    "print(\"\\n=== Plotting ALL stations (2 figs/station) ===\")\n",
    "for j in range(N):\n",
    "    station_id = int(use_idx[j])\n",
    "\n",
    "    ytrue_fig1 = ytrue_roll[w0, :, j]\n",
    "    yhat_fig1 = yhat_roll[w0, :, j]\n",
    "\n",
    "    plt.figure(figsize=(9, 4), dpi=140)\n",
    "    plt.plot(range(H), ytrue_fig1, \"-o\", linewidth=2, markersize=3, label=\"True (scaled)\")\n",
    "    plt.plot(range(H), yhat_fig1, \"-o\", linewidth=2, markersize=3, label=\"Pred (scaled)\")\n",
    "    plt.title(f\"FIG1 VARX-FREEZE | Beijing st_{station_id} | first rolling window | H={H} | P={P}\")\n",
    "    plt.xlabel(\"3-hour step within window\")\n",
    "    plt.ylabel(\"Scaled t\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PLOTS_DIR / f\"FIG1_VARX_freeze_wdSinCos_st{station_id}_H{H}_P{P}_scaled.png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(12, 4), dpi=140)\n",
    "    plt.plot(times_fig2, ytrue_stitched[:, j], \"-\", linewidth=2, label=\"True (scaled)\")\n",
    "    plt.plot(times_fig2, yhat_stitched[:, j], \"-\", linewidth=2, label=\"Pred (scaled)\")\n",
    "    plt.title(f\"FIG2 VARX-FREEZE | Beijing st_{station_id} | full TEST (stitched) | H={H} | P={P}\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Scaled t\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PLOTS_DIR / f\"FIG2_VARX_freeze_wdSinCos_st{station_id}_H{H}_P{P}_scaled.png\")\n",
    "    plt.close()\n",
    "\n",
    "print(f\"Saved plots to: {PLOTS_DIR.resolve()}\")\n",
    "print(\"All done.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial-neural-adapter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
