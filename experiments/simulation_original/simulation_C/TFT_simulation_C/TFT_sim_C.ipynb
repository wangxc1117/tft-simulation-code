{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb75176b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangxc1117/miniconda3/envs/geospatial-neural-adapter/lib/python3.10/site-packages/fs/__init__.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)  # type: ignore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded spatial_utils from: /home/wangxc1117/geospatial-neural-adapter/geospatial_neural_adapter/cpp_extensions/spatial_utils.so\n",
      "Device: cuda\n",
      "Synthetic (Scenario C) y shape : (1500, 36)\n",
      "Synthetic (Scenario C) cont shape: (1500, 36, 3)\n",
      "Total time steps: 1500\n",
      "Number of points: 36\n",
      "Freq: 1H\n",
      "\n",
      "=== Split (by time index) ===\n",
      "Train: 0 -> 1049 | len = 1050\n",
      "Val  : 1050 -> 1274 | len = 225\n",
      "Test : 1275 -> 1499 | len = 225\n",
      "\n",
      "=== After pooled scaling (train-only) ===\n",
      "Y_scaled: (1500, 36) | finite: True\n",
      "X_scaled: (1500, 36, 3) | finite: True\n",
      "\n",
      "Built TimeSeries (Scenario C):\n",
      "Targets: 36\n",
      "Past covs: 36\n",
      "\n",
      "=== INTERNAL validation (Scenario C, for early stopping only) ===\n",
      "Train len: 1050\n",
      "IntVal idx: 810 -> 1049 | len = 240\n",
      "IntVal time: 2000-02-03 18:00:00 -> 2000-02-13 17:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training TFT (Scenario C: strongly nonlinear world) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                              | Type                             | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | train_metrics                     | MetricCollection                 | 0      | train\n",
      "1  | val_metrics                       | MetricCollection                 | 0      | train\n",
      "2  | input_embeddings                  | _MultiEmbedding                  | 0      | train\n",
      "3  | static_covariates_vsn             | _VariableSelectionNetwork        | 5.0 K  | train\n",
      "4  | encoder_vsn                       | _VariableSelectionNetwork        | 8.8 K  | train\n",
      "5  | decoder_vsn                       | _VariableSelectionNetwork        | 1.6 K  | train\n",
      "6  | static_context_grn                | _GatedResidualNetwork            | 16.8 K | train\n",
      "7  | static_context_hidden_encoder_grn | _GatedResidualNetwork            | 16.8 K | train\n",
      "8  | static_context_cell_encoder_grn   | _GatedResidualNetwork            | 16.8 K | train\n",
      "9  | static_context_enrichment         | _GatedResidualNetwork            | 16.8 K | train\n",
      "10 | lstm_encoder                      | LSTM                             | 33.3 K | train\n",
      "11 | lstm_decoder                      | LSTM                             | 33.3 K | train\n",
      "12 | post_lstm_gan                     | _GateAddNorm                     | 8.4 K  | train\n",
      "13 | static_enrichment_grn             | _GatedResidualNetwork            | 20.9 K | train\n",
      "14 | multihead_attn                    | _InterpretableMultiHeadAttention | 10.4 K | train\n",
      "15 | post_attn_gan                     | _GateAddNorm                     | 8.4 K  | train\n",
      "16 | feed_forward_block                | _GatedResidualNetwork            | 16.8 K | train\n",
      "17 | pre_output_gan                    | _GateAddNorm                     | 8.4 K  | train\n",
      "18 | output_layer                      | Linear                           | 1.1 K  | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "223 K     Trainable params\n",
      "0         Non-trainable params\n",
      "223 K     Total params\n",
      "0.894     Total estimated model params size (MB)\n",
      "276       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e106c06f4bce47219fab44d0570c09bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "368453ff93164df6a8b7c401fb460636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d6f1ec4f914e368efe3f405e69e855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36771f68dd834c6b893a0d9107f89e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "226e3a91dbc843fa8aa87f32b449a372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce3516f304de4b408cc971d510a1fe5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec2f56769904cfa95eb37ff3b52906d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba4d3bbbe3b485484174ecb879c0a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ccaf79aa56942b6825daaf1585f0be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a397221d9344d86b85eba920f714174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fdb5d53ac704bdfbb6a1f51bbe6f697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c9df27742b14543920c32a435122945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dbfe5ac88b84ea2a64ae4e08f00bfac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81b7b53a19aa4ce886644e60b5c22cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da9e2bf833f48dab248cb95fed65f20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d3be07618534b6f9319ebcc86a1f1be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de19e84dc2d455aab29a149b16b35e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52d30c7d0a5e419198d831ddb57fff8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1785bca879e4415994e9858408d10414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f072d43edf5490f9f8d1384c8aec89d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f7f10279ab49d78aacd3ec5a9e944d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a81275cc08b4d8eb0c8a33b104e1d9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f114583fd84bee83e49fe111782223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ed53d4e7994783bc22b23084abf882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a86f35baa534814b1ccd0fd735cb933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27a6a08af5954bb6b2af8b04c71a512d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7858a3e485a74dd3abd41347aa6f2b29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "422ceabd1f0740bc8b1f0a7eaf095189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad6999f9fbdd43d6b180c2754c2e82e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe2f8bea7e24ac5825cce6be35c79b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d87edd3f3c2b4042b4cc3a16ddd57536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6edbfbfd72c41cd9b9af76ad353e17a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Loading best checkpoint ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Rolling non-overlap (Scenario C, POOLED, TEST) ===\n",
      "windows=9 | step=24 | each window predicts H=24 | points=36\n",
      "RMSE: 2.2431708648405784\n",
      "MAE : 1.5593161582946777\n",
      "\n",
      "=== P50 q-risk (Scenario C, ROLLING, TEST) ===\n",
      "scaled  : 1.0625774248858555\n",
      "unscaled: 0.16229374846494293\n",
      "\n",
      "=== Plotting 2 figs per grid point (Scenario C) ===\n",
      "Saved 2 figs/point for 36 points under: /home/wangxc1117/TFTModel-use/geospatial-neural-adapter-dev/examples/try/simulation/TFT_simulation_C/TFT_plots_synth_tft_C_2figs\n",
      "\n",
      "All done (Scenario C: strongly nonlinear world).\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.models import TFTModel\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "from geospatial_neural_adapter.data.preprocessing import prepare_all_with_scaling\n",
    "from geospatial_neural_adapter.data.generators import generate_time_synthetic_data\n",
    "\n",
    "\n",
    "# Global settings & dirs\n",
    "GLOBAL_SEED = 42\n",
    "np.random.seed(GLOBAL_SEED)\n",
    "torch.manual_seed(GLOBAL_SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "try:\n",
    "    EXP_ROOT = Path(__file__).resolve().parent\n",
    "except NameError:\n",
    "    EXP_ROOT = Path.cwd()\n",
    "\n",
    "CKPT_DIR = (EXP_ROOT / \"darts_ckpt_synth_tft_C\").resolve()\n",
    "RUNS_DIR = (EXP_ROOT / \"TFT_runs_synth_tft_C\").resolve()\n",
    "PLOTS_DIR = (EXP_ROOT / \"TFT_plots_synth_tft_C_2figs\").resolve()\n",
    "\n",
    "CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RUNS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# Generate synthetic data\n",
    "N_POINTS = 36\n",
    "T_TOTAL = 1500\n",
    "EIGENVALUE = 3.0\n",
    "\n",
    "locs = np.linspace(-5.0, 5.0, N_POINTS).astype(np.float32)\n",
    "\n",
    "cat_synth, cont_synth, y_synth = generate_time_synthetic_data(\n",
    "    locs=locs,\n",
    "    n_time_steps=T_TOTAL,\n",
    "    noise_std=0.6,\n",
    "    eigenvalue=EIGENVALUE,\n",
    "    eta_rho=0.8,\n",
    "    f_rho=0.6,\n",
    "    global_mean=50.0,\n",
    "    feature_noise_std=0.5,\n",
    "    non_linear_strength=2.0,\n",
    "    seed=GLOBAL_SEED,\n",
    ")\n",
    "\n",
    "print(\"Synthetic y shape :\", y_synth.shape)\n",
    "print(\"Synthetic cont shape:\", cont_synth.shape)\n",
    "\n",
    "Y = y_synth.astype(np.float32)\n",
    "X = cont_synth.astype(np.float32)\n",
    "\n",
    "T_total, N = Y.shape\n",
    "P_time = X.shape[2]\n",
    "\n",
    "time_start = pd.Timestamp(\"2000-01-01 00:00:00\")\n",
    "time_index = pd.date_range(start=time_start, periods=T_total, freq=\"1H\")\n",
    "freq = \"1H\"\n",
    "if len(time_index) != T_total:\n",
    "    raise RuntimeError(\"Global time_index length mismatch.\")\n",
    "\n",
    "print(\"Total time steps:\", T_total)\n",
    "print(\"Number of points:\", N)\n",
    "print(\"Freq:\", freq)\n",
    "\n",
    "PAST_COV_COLS = [\"f1\", \"f2\", \"f3\"]\n",
    "cat_dummy = np.zeros((T_total, N, 1), dtype=np.int64)\n",
    "\n",
    "\n",
    "# Split & scaling\n",
    "train_ratio = 0.70\n",
    "val_ratio = 0.15\n",
    "\n",
    "cut_train = int(T_total * train_ratio)\n",
    "cut_val = int(T_total * (train_ratio + val_ratio))\n",
    "if not (0 < cut_train < cut_val < T_total):\n",
    "    raise ValueError(\"Bad split indices computed from ratios.\")\n",
    "\n",
    "print(\"Train:\", 0, \"->\", cut_train - 1, \"| len =\", cut_train)\n",
    "print(\"Val  :\", cut_train, \"->\", cut_val - 1, \"| len =\", cut_val - cut_train)\n",
    "print(\"Test :\", cut_val, \"->\", T_total - 1, \"| len =\", T_total - cut_val)\n",
    "\n",
    "train_ds, val_ds, test_ds, preprocessor = prepare_all_with_scaling(\n",
    "    cat_features=cat_dummy,\n",
    "    cont_features=X,\n",
    "    targets=Y,\n",
    "    train_ratio=train_ratio,\n",
    "    val_ratio=val_ratio,\n",
    "    feature_scaler_type=\"standard\",\n",
    "    target_scaler_type=\"standard\",\n",
    "    fit_on_train_only=True,\n",
    ")\n",
    "\n",
    "def stitch_targets(dsets) -> np.ndarray:\n",
    "    return np.concatenate(\n",
    "        [ds.tensors[2].detach().cpu().numpy().astype(np.float32) for ds in dsets],\n",
    "        axis=0,\n",
    "    )\n",
    "\n",
    "def stitch_cont_features(dsets) -> np.ndarray:\n",
    "    return np.concatenate(\n",
    "        [ds.tensors[1].detach().cpu().numpy().astype(np.float32) for ds in dsets],\n",
    "        axis=0,\n",
    "    )\n",
    "\n",
    "Y_scaled = stitch_targets([train_ds, val_ds, test_ds])\n",
    "X_scaled = stitch_cont_features([train_ds, val_ds, test_ds])\n",
    "\n",
    "if Y_scaled.shape != Y.shape:\n",
    "    raise ValueError(f\"Y_scaled shape {Y_scaled.shape} != Y {Y.shape}\")\n",
    "if X_scaled.shape != X.shape:\n",
    "    raise ValueError(f\"X_scaled shape {X_scaled.shape} != X {X.shape}\")\n",
    "\n",
    "print(\"Y_scaled:\", Y_scaled.shape, \"| finite:\", bool(np.isfinite(Y_scaled).all()))\n",
    "print(\"X_scaled:\", X_scaled.shape, \"| finite:\", bool(np.isfinite(X_scaled).all()))\n",
    "\n",
    "\n",
    "# Build TimeSeries (target + past cov + static)\n",
    "series_all = []\n",
    "pcov_all = []\n",
    "\n",
    "K_LAT = 6\n",
    "K_LON = 6\n",
    "if K_LAT * K_LON != N:\n",
    "    lat_pts = np.linspace(-5.0, 5.0, N).astype(np.float32)\n",
    "    lon_pts = np.zeros_like(lat_pts, dtype=np.float32)\n",
    "else:\n",
    "    lat_lin = np.linspace(18.0, 53.6, K_LAT, dtype=np.float32)\n",
    "    lon_lin = np.linspace(73.5, 134.8, K_LON, dtype=np.float32)\n",
    "    lat_grid, lon_grid = np.meshgrid(lat_lin, lon_lin, indexing=\"ij\")\n",
    "    lat_pts = lat_grid.reshape(-1).astype(np.float32)\n",
    "    lon_pts = lon_grid.reshape(-1).astype(np.float32)\n",
    "\n",
    "alt_pts = np.zeros_like(lat_pts, dtype=np.float32)\n",
    "\n",
    "for j in range(N):\n",
    "    name = f\"grid_{j:03d}\"\n",
    "\n",
    "    ts = TimeSeries.from_times_and_values(\n",
    "        times=time_index,\n",
    "        values=Y_scaled[:, j:j + 1].astype(np.float32),\n",
    "        columns=[name],\n",
    "        freq=freq,\n",
    "    )\n",
    "\n",
    "    sc = pd.DataFrame(\n",
    "        {\"lat\": [float(lat_pts[j])], \"lon\": [float(lon_pts[j])], \"alt\": [float(alt_pts[j])]},\n",
    "        index=[name],\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "\n",
    "    ts = ts.with_static_covariates(sc)\n",
    "    series_all.append(ts)\n",
    "\n",
    "    pc = TimeSeries.from_times_and_values(\n",
    "        times=time_index,\n",
    "        values=X_scaled[:, j, :].astype(np.float32),\n",
    "        columns=[f\"{name}_{c}\" for c in PAST_COV_COLS],\n",
    "        freq=freq,\n",
    "    ).with_static_covariates(sc)\n",
    "\n",
    "    pcov_all.append(pc)\n",
    "\n",
    "print(\"Targets:\", len(series_all))\n",
    "print(\"Past covs:\", len(pcov_all))\n",
    "\n",
    "\n",
    "# Internal validation for early stopping\n",
    "L, H = 56, 24\n",
    "INTERNAL_VAL_STEPS = 240\n",
    "\n",
    "def slice_list(xs, a, b):\n",
    "    return [x[a:b] for x in xs]\n",
    "\n",
    "train_series = slice_list(series_all, 0, cut_train)\n",
    "train_pcov = slice_list(pcov_all, 0, cut_train)\n",
    "\n",
    "iv_start = max(0, cut_train - INTERNAL_VAL_STEPS)\n",
    "iv_end = cut_train\n",
    "\n",
    "min_needed = L + H\n",
    "if (iv_end - iv_start) < min_needed:\n",
    "    iv_start = max(0, iv_end - min_needed)\n",
    "\n",
    "val_series = slice_list(series_all, iv_start, iv_end)\n",
    "val_pcov = slice_list(pcov_all, iv_start, iv_end)\n",
    "\n",
    "print(\"Train len:\", len(train_series[0]))\n",
    "print(\"IntVal idx:\", iv_start, \"->\", iv_end - 1, \"| len =\", len(val_series[0]))\n",
    "print(\"IntVal time:\", time_index[iv_start], \"->\", time_index[iv_end - 1])\n",
    "\n",
    "\n",
    "# Train TFT\n",
    "MODEL_NAME = f\"tft_synth_C_L{L}_H{H}_seed{GLOBAL_SEED}\"\n",
    "LOG_ROOT = (RUNS_DIR / f\"seed_{GLOBAL_SEED}\").resolve()\n",
    "LOG_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "tft = TFTModel(\n",
    "    input_chunk_length=L,\n",
    "    output_chunk_length=H,\n",
    "    n_epochs=30,\n",
    "    hidden_size=64,\n",
    "    num_attention_heads=4,\n",
    "    dropout=0.1,\n",
    "    batch_size=32,\n",
    "    optimizer_kwargs={\"lr\": 3e-4},\n",
    "    add_relative_index=True,\n",
    "    random_state=GLOBAL_SEED,\n",
    "    force_reset=True,\n",
    "    model_name=MODEL_NAME,\n",
    "    work_dir=str(CKPT_DIR),\n",
    "    save_checkpoints=True,\n",
    "    pl_trainer_kwargs={\n",
    "        \"accelerator\": \"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "        \"devices\": 1,\n",
    "        \"enable_progress_bar\": True,\n",
    "        \"enable_model_summary\": False,\n",
    "        \"enable_checkpointing\": True,\n",
    "        \"callbacks\": [EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=6)],\n",
    "        \"logger\": CSVLogger(save_dir=str(LOG_ROOT), name=MODEL_NAME),\n",
    "        \"gradient_clip_val\": 1.0,\n",
    "    },\n",
    ")\n",
    "\n",
    "tft.fit(\n",
    "    series=train_series,\n",
    "    past_covariates=train_pcov,\n",
    "    val_series=val_series,\n",
    "    val_past_covariates=val_pcov,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "tft = TFTModel.load_from_checkpoint(model_name=MODEL_NAME, work_dir=str(CKPT_DIR), best=True)\n",
    "print(\"Loaded best checkpoint.\")\n",
    "\n",
    "\n",
    "# Rolling non-overlap over TEST\n",
    "def rolling_nonoverlap(model, series, pcov, start, end, L, H):\n",
    "    yh, yt = [], []\n",
    "    t0_list = []\n",
    "    for t0 in range(start, end - H + 1, H):\n",
    "        if t0 < L:\n",
    "            continue\n",
    "        ctx_s = [s[:t0] for s in series]\n",
    "        ctx_p = [p[:t0] for p in pcov]\n",
    "        preds = model.predict(n=H, series=ctx_s, past_covariates=ctx_p, verbose=False)\n",
    "        preds = preds if isinstance(preds, list) else [preds]\n",
    "        yh.append(np.stack([p.values(copy=False)[:, 0] for p in preds], axis=1).astype(np.float32))\n",
    "        yt.append(np.stack([s[t0:t0 + H].values(copy=False)[:, 0] for s in series], axis=1).astype(np.float32))\n",
    "        t0_list.append(int(t0))\n",
    "\n",
    "    if len(yh) == 0:\n",
    "        raise RuntimeError(\"No rolling windows produced. Check start/end/L/H.\")\n",
    "    return np.stack(yh, axis=0), np.stack(yt, axis=0), t0_list\n",
    "\n",
    "test_start = cut_val\n",
    "start_ctx = max(test_start, L)\n",
    "yhat_roll, ytrue_roll, t0_list = rolling_nonoverlap(tft, series_all, pcov_all, start_ctx, T_total, L, H)\n",
    "\n",
    "W = yhat_roll.shape[0]\n",
    "print(\"windows=\", W, \"| step=\", H, \"| each window predicts H=\", H, \"| points=\", N)\n",
    "\n",
    "diff = yhat_roll - ytrue_roll\n",
    "rmse = float(np.sqrt(np.mean(diff ** 2)))\n",
    "mae = float(np.mean(np.abs(diff)))\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAE :\", mae)\n",
    "\n",
    "\n",
    "# q-risk\n",
    "def qrisk(y_true, y_pred, q=0.5, eps=1e-8):\n",
    "    y_true = np.asarray(y_true, dtype=np.float64)\n",
    "    y_pred = np.asarray(y_pred, dtype=np.float64)\n",
    "    e = y_true - y_pred\n",
    "    return float(2.0 * np.sum(np.maximum(q * e, (q - 1) * e)) / (np.sum(np.abs(y_true)) + eps))\n",
    "\n",
    "yhat_f = yhat_roll.reshape(-1, N)\n",
    "ytrue_f = ytrue_roll.reshape(-1, N)\n",
    "\n",
    "print(\"scaled  :\", qrisk(ytrue_f, yhat_f))\n",
    "\n",
    "ytrue_un = preprocessor.inverse_transform_targets(ytrue_f)\n",
    "yhat_un = preprocessor.inverse_transform_targets(yhat_f)\n",
    "print(\"unscaled:\", qrisk(ytrue_un, yhat_un))\n",
    "\n",
    "\n",
    "# Plots\n",
    "test_end = T_total\n",
    "test_len = test_end - test_start\n",
    "\n",
    "y_true_test = Y_scaled[test_start:test_end, :].astype(np.float32)\n",
    "\n",
    "y_pred_test = np.full((test_len, N), np.nan, dtype=np.float32)\n",
    "for w, t0 in enumerate(t0_list):\n",
    "    a = t0 - test_start\n",
    "    b = a + H\n",
    "    if a < 0 or b > test_len:\n",
    "        continue\n",
    "    y_pred_test[a:b, :] = yhat_roll[w]\n",
    "\n",
    "w0 = 0\n",
    "t0_first = t0_list[w0]\n",
    "dates_first = time_index[t0_first:t0_first + H]\n",
    "dates_test = time_index[test_start:test_end]\n",
    "\n",
    "def plot_two_figs_all_points(out_dir: Path):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for j in range(N):\n",
    "        y_true_H = ytrue_roll[w0][:, j]\n",
    "        y_pred_H = yhat_roll[w0][:, j]\n",
    "\n",
    "        plt.figure(figsize=(10, 4), dpi=140)\n",
    "        plt.plot(dates_first, y_true_H, \"-o\", linewidth=2, markersize=3, label=\"True\")\n",
    "        plt.plot(dates_first, y_pred_H, \"-o\", linewidth=2, markersize=3, label=\"Pred\")\n",
    "        plt.title(f\"FIG1 Synthetic C | grid_{j:03d} | TEST first {H} steps | y (scaled)\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Scaled target\")\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(out_dir / f\"FIG1_grid{j:03d}_test_firstH{H}_t0{t0_first}.png\")\n",
    "        plt.close()\n",
    "\n",
    "        y_true_all = y_true_test[:, j]\n",
    "        y_pred_all = y_pred_test[:, j]\n",
    "\n",
    "        plt.figure(figsize=(12, 4), dpi=140)\n",
    "        plt.plot(dates_test, y_true_all, \"-\", linewidth=1.8, label=\"True\")\n",
    "        plt.plot(dates_test, y_pred_all, \"-\", linewidth=1.8, label=\"Pred (stitched rolling)\")\n",
    "        plt.axvline(time_index[test_start], linestyle=\"--\", linewidth=1, label=\"TEST start\")\n",
    "        plt.title(f\"FIG2 Synthetic C | grid_{j:03d} | ALL TEST | y (scaled)\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Scaled target\")\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(out_dir / f\"FIG2_grid{j:03d}_test_all_stitched_step{H}.png\")\n",
    "        plt.close()\n",
    "\n",
    "    print(f\"Saved 2 figs/point for {N} points under: {out_dir}\")\n",
    "\n",
    "plot_two_figs_all_points(PLOTS_DIR)\n",
    "\n",
    "print(\"All done.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial-neural-adapter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
