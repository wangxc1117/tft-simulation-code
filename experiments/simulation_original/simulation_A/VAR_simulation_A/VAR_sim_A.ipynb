{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c761bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded spatial_utils from: /home/wangxc1117/geospatial-neural-adapter/geospatial_neural_adapter/cpp_extensions/spatial_utils.so\n",
      "Device: cuda\n",
      "Y shape   : (1500, 36)\n",
      "X_cov shape: (1500, 36, 3)\n",
      "\n",
      "=== Split (by time index) ===\n",
      "Train: 0 -> 1049 | len = 1050\n",
      "Val  : 1050 -> 1274 | len = 225\n",
      "Test : 1275 -> 1499 | len = 225\n",
      "\n",
      "=== Train design (VARX) ===\n",
      "Xtr: (1049, 145) Ytr: (1049, 36)\n",
      "B shape (coeff matrix): (145, 36)\n",
      "\n",
      "=== VARX TFT-aligned (Synthetic Scenario A, POOLED, TEST, NO future cov) ===\n",
      "windows=9 | step=24 | H=24 | N=36\n",
      "RMSE: 1.2062946557998657\n",
      "MAE : 0.9611192345619202\n",
      "\n",
      "=== P50 q-risk (Synthetic Scenario A, NO future cov) ===\n",
      "scaled  : 0.8045394427193219\n",
      "unscaled: 0.013991723780361455\n",
      "\n",
      "All done (VARX baseline, Scenario A, NO future cov).\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from geospatial_neural_adapter.data.preprocessing import prepare_all_with_scaling\n",
    "from geospatial_neural_adapter.data.generators import generate_time_synthetic_data\n",
    "\n",
    "GLOBAL_SEED = 42\n",
    "np.random.seed(GLOBAL_SEED)\n",
    "torch.manual_seed(GLOBAL_SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "P = 1             \n",
    "L = 56            \n",
    "H = 24            \n",
    "STEP = H          \n",
    "\n",
    "train_ratio = 0.70\n",
    "val_ratio   = 0.15\n",
    "\n",
    "N_POINTS  = 36\n",
    "T_TOTAL   = 1500\n",
    "EIGENVALUE = 3.0\n",
    "\n",
    "# Plots\n",
    "PLOTS_DIR = Path(\"VAR_synth_A_TFTaligned\")\n",
    "FIG1_DIR  = PLOTS_DIR / \"FIG1_first\"\n",
    "FIG2_DIR  = PLOTS_DIR / \"FIG2_stitched\"\n",
    "FIG1_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG2_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# Generate synthetic data\n",
    "\n",
    "locs = np.linspace(-5.0, 5.0, N_POINTS).astype(np.float32)  # (N,)\n",
    "\n",
    "cat_synth, cont_synth, y_synth = generate_time_synthetic_data(\n",
    "    locs=locs,\n",
    "    n_time_steps=T_TOTAL,\n",
    "    noise_std=0.3,\n",
    "    eigenvalue=EIGENVALUE,\n",
    "    eta_rho=0.8,\n",
    "    f_rho=0.6,\n",
    "    global_mean=50.0,\n",
    "    feature_noise_std=0.0,\n",
    "    non_linear_strength=0.0,\n",
    "    seed=GLOBAL_SEED,\n",
    ")\n",
    "\n",
    "Y = y_synth.astype(np.float32)          \n",
    "X_cov = cont_synth.astype(np.float32)   \n",
    "\n",
    "T_total, N = Y.shape\n",
    "_, _, P_cov = X_cov.shape\n",
    "\n",
    "print(\"Y shape   :\", Y.shape)\n",
    "print(\"X_cov shape:\", X_cov.shape)\n",
    "\n",
    "time_start = pd.Timestamp(\"2000-01-01 00:00:00\")\n",
    "time_index = pd.date_range(start=time_start, periods=T_total, freq=\"1H\")\n",
    "\n",
    "cat_dummy = np.zeros((T_total, N, 1), dtype=np.int64)\n",
    "\n",
    "\n",
    "# Scaling \n",
    "\n",
    "train_ds, val_ds, test_ds, preprocessor = prepare_all_with_scaling(\n",
    "    cat_features=cat_dummy,\n",
    "    cont_features=X_cov,        \n",
    "    targets=Y,\n",
    "    train_ratio=train_ratio,\n",
    "    val_ratio=val_ratio,\n",
    "    feature_scaler_type=\"standard\",\n",
    "    target_scaler_type=\"standard\",\n",
    "    fit_on_train_only=True,\n",
    ")\n",
    "\n",
    "def stitch(dsets):\n",
    "    X = np.concatenate(\n",
    "        [d.tensors[1].cpu().numpy().astype(np.float32) for d in dsets],\n",
    "        axis=0,\n",
    "    )\n",
    "    y = np.concatenate(\n",
    "        [d.tensors[2].cpu().numpy().astype(np.float32) for d in dsets],\n",
    "        axis=0,\n",
    "    )\n",
    "    return X, y\n",
    "\n",
    "X_s, y_s = stitch([train_ds, val_ds, test_ds])  \n",
    "\n",
    "if X_s.shape != X_cov.shape:\n",
    "    raise ValueError(f\"X_s shape {X_s.shape} != X_cov {X_cov.shape}\")\n",
    "if y_s.shape != Y.shape:\n",
    "    raise ValueError(f\"y_s shape {y_s.shape} != Y {Y.shape}\")\n",
    "\n",
    "cut_train = int(T_total * train_ratio)\n",
    "cut_val   = int(T_total * (train_ratio + val_ratio))\n",
    "test_start = cut_val\n",
    "\n",
    "print(\"\\n=== Split (by time index) ===\")\n",
    "print(\"Train:\", 0, \"->\", cut_train - 1, \"| len =\", cut_train)\n",
    "print(\"Val  :\", cut_train, \"->\", cut_val - 1, \"| len =\", cut_val - cut_train)\n",
    "print(\"Test :\", cut_val, \"->\", T_total - 1, \"| len =\", T_total - cut_val)\n",
    "\n",
    "\n",
    "# Build VARX design matrix \n",
    "\n",
    "def build_varx_design(\n",
    "    y: np.ndarray,\n",
    "    x: np.ndarray,\n",
    "    t_start: int,\n",
    "    t_end: int,\n",
    "    p: int,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Build pooled VARX design:\n",
    "      For each t in [t_start, t_end):\n",
    "        feat(t) = [1, vec(Y_{t-1..t-p}), vec(X_t)]\n",
    "        target  = Y_t\n",
    "\n",
    "    Args:\n",
    "        y: (T, N) scaled target\n",
    "        x: (T, N, P_cov) scaled cov\n",
    "        t_start: int >= p\n",
    "        t_end: int <= T\n",
    "        p: VAR order\n",
    "\n",
    "    Returns:\n",
    "        X_design: (M, D)\n",
    "        Y_design: (M, N)\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    ys   = []\n",
    "    for t in range(t_start, t_end):\n",
    "        lag_list = []\n",
    "        for i in range(1, p + 1):\n",
    "            lag_list.append(y[t - i])        \n",
    "        lag_vec = np.concatenate(lag_list, axis=0)  \n",
    "\n",
    "        x_vec = x[t].reshape(-1)             \n",
    "\n",
    "        feat = np.concatenate([[1.0], lag_vec, x_vec]).astype(np.float32)\n",
    "        rows.append(feat)\n",
    "        ys.append(y[t])                      \n",
    "\n",
    "    X_design = np.stack(rows, axis=0)       \n",
    "    Y_design = np.stack(ys, axis=0)          \n",
    "    return X_design, Y_design\n",
    "\n",
    "Xtr, Ytr = build_varx_design(\n",
    "    y=y_s,\n",
    "    x=X_s,\n",
    "    t_start=P,       \n",
    "    t_end=cut_train,\n",
    "    p=P,\n",
    ")\n",
    "\n",
    "print(\"\\n=== Train design (VARX) ===\")\n",
    "print(\"Xtr:\", Xtr.shape, \"Ytr:\", Ytr.shape)\n",
    "\n",
    "Xtr_t = torch.from_numpy(Xtr).double().to(DEVICE) \n",
    "Ytr_t = torch.from_numpy(Ytr).double().to(DEVICE)  \n",
    "\n",
    "B, *_ = torch.linalg.lstsq(Xtr_t, Ytr_t)\n",
    "B = B.float().cpu().numpy()\n",
    "\n",
    "print(\"B shape (coeff matrix):\", B.shape)\n",
    "\n",
    "# Rolling recursive VARX\n",
    "\n",
    "def qrisk(y_true: np.ndarray, y_pred: np.ndarray, q: float = 0.5, eps: float = 1e-8) -> float:\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    e = y_true - y_pred\n",
    "    return float(\n",
    "        2.0 * np.sum(np.maximum(q * e, (q - 1) * e)) / (np.sum(np.abs(y_true)) + eps)\n",
    "    )\n",
    "\n",
    "def rolling_varx(\n",
    "    y: np.ndarray,\n",
    "    x: np.ndarray,\n",
    "    B: np.ndarray,\n",
    "    start_ctx: int,\n",
    "    end_T: int,\n",
    "    p: int,\n",
    "    H: int,\n",
    "    step: int,\n",
    "):\n",
    "\n",
    "    t0_candidates = range(start_ctx, end_T - H + 1, step)\n",
    "    yh_list = []\n",
    "    yt_list = []\n",
    "    t0_list = []\n",
    "\n",
    "    for t0 in t0_candidates:\n",
    "        if t0 < p:\n",
    "            continue\n",
    "\n",
    "        hist = [y[t0 - i].copy() for i in range(1, p + 1)] \n",
    "\n",
    "        x_vec_frozen = x[t0 - 1].reshape(-1)              \n",
    "    \n",
    "        ytrue = y[t0:t0 + H].copy()                         \n",
    "        yhat  = np.empty_like(ytrue)                      \n",
    "\n",
    "        for k in range(H):\n",
    "            lag_vec = np.concatenate(hist, axis=0)         \n",
    "\n",
    "            feat = np.concatenate([[1.0], lag_vec, x_vec_frozen]).astype(np.float32) \n",
    "            pred = feat @ B                                 \n",
    "            yhat[k] = pred\n",
    "\n",
    "            hist = [pred] + hist[:p - 1]\n",
    "\n",
    "        yh_list.append(yhat)\n",
    "        yt_list.append(ytrue)\n",
    "        t0_list.append(t0)\n",
    "\n",
    "    if len(yh_list) == 0:\n",
    "        raise RuntimeError(\"No rolling windows produced. Check start_ctx/end_T/H/step.\")\n",
    "\n",
    "    return np.stack(yh_list, axis=0), np.stack(yt_list, axis=0), t0_list\n",
    "\n",
    "start_ctx = max(test_start, L, P)\n",
    "yhat_roll, ytrue_roll, t0_list = rolling_varx(\n",
    "    y=y_s,\n",
    "    x=X_s,\n",
    "    B=B,\n",
    "    start_ctx=start_ctx,\n",
    "    end_T=T_total,\n",
    "    p=P,\n",
    "    H=H,\n",
    "    step=STEP,\n",
    ")\n",
    "\n",
    "W = yhat_roll.shape[0]\n",
    "diff = yhat_roll - ytrue_roll\n",
    "rmse = float(np.sqrt(np.mean(diff ** 2)))\n",
    "mae  = float(np.mean(np.abs(diff)))\n",
    "\n",
    "print(\"\\n=== VARX TFT-aligned (Synthetic Scenario A, POOLED, TEST, NO future cov) ===\")\n",
    "print(f\"windows={W} | step={STEP} | H={H} | N={N}\")\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAE :\", mae)\n",
    "\n",
    "yhat_f = yhat_roll.reshape(-1, N)\n",
    "ytrue_f = ytrue_roll.reshape(-1, N)\n",
    "\n",
    "qr_scaled = qrisk(ytrue_f, yhat_f)\n",
    "ytrue_un = preprocessor.inverse_transform_targets(ytrue_f)\n",
    "yhat_un = preprocessor.inverse_transform_targets(yhat_f)\n",
    "qr_unscaled = qrisk(ytrue_un, yhat_un)\n",
    "\n",
    "print(\"\\n=== P50 q-risk (Synthetic Scenario A, NO future cov) ===\")\n",
    "print(\"scaled  :\", qr_scaled)\n",
    "print(\"unscaled:\", qr_unscaled)\n",
    "\n",
    "\n",
    "# plots\n",
    "\n",
    "t0_first = t0_list[0]\n",
    "times1   = time_index[t0_first:t0_first + H]\n",
    "\n",
    "st_ytrue = ytrue_roll.reshape(W * H, N)\n",
    "st_yhat  = yhat_roll.reshape(W * H, N)\n",
    "times2   = time_index[t0_first:t0_first + W * H]\n",
    "\n",
    "for j in range(N):\n",
    "    plt.figure(figsize=(9, 4), dpi=140)\n",
    "    plt.plot(range(H), ytrue_roll[0, :, j], \"-o\", label=\"True\")\n",
    "    plt.plot(range(H), yhat_roll[0, :, j], \"-o\", label=\"Pred\")\n",
    "    plt.title(f\"FIG1 VARX Synth A | grid{j:03d}\")\n",
    "    plt.xlabel(\"step\")\n",
    "    plt.ylabel(\"Scaled y\")\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIG1_DIR / f\"FIG1_VAR_grid{j:03d}.png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(12, 4), dpi=140)\n",
    "    plt.plot(times2, st_ytrue[:, j], label=\"True\")\n",
    "    plt.plot(times2, st_yhat[:, j], label=\"Pred\")\n",
    "    plt.axvline(time_index[test_start], linestyle=\"--\", linewidth=1, label=\"TEST start\")\n",
    "    plt.title(f\"FIG2 VARX Synth A | grid{j:03d}\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Scaled y\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIG2_DIR / f\"FIG2_VAR_grid{j:03d}.png\")\n",
    "    plt.close()\n",
    "\n",
    "print(\"\\nAll done (VARX baseline, Scenario A, NO future cov).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial-neural-adapter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
