{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb75176b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangxc1117/miniconda3/envs/geospatial-neural-adapter/lib/python3.10/site-packages/fs/__init__.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)  # type: ignore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded spatial_utils from: /home/wangxc1117/geospatial-neural-adapter/geospatial_neural_adapter/cpp_extensions/spatial_utils.so\n",
      "Device: cuda\n",
      "Synthetic (A′) y shape: (1500, 36)\n",
      "Synthetic (A′) cont shape: (1500, 36, 3)\n",
      "Total time steps: 1500\n",
      "Number of points: 36\n",
      "Freq: 1H\n",
      "\n",
      "=== Split (by time index) [Scenario A′] ===\n",
      "Train: 0 -> 1049 | len = 1050\n",
      "Val  : 1050 -> 1274 | len = 225\n",
      "Test : 1275 -> 1499 | len = 225\n",
      "\n",
      "=== After pooled scaling (train-only, A′) ===\n",
      "Y_scaled: (1500, 36) | finite: True\n",
      "X_scaled: (1500, 36, 3) | finite: True\n",
      "\n",
      "Built TimeSeries (Scenario A′):\n",
      "Targets: 36\n",
      "Past covs: 36\n",
      "\n",
      "=== INTERNAL validation (A′, for early stopping only) ===\n",
      "Train len: 1050\n",
      "IntVal idx: 810 -> 1049 | len = 240\n",
      "IntVal time: 2000-02-03 18:00:00 -> 2000-02-13 17:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training TFT (Scenario A′: linear world, eta_rho=0.6) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                              | Type                             | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | train_metrics                     | MetricCollection                 | 0      | train\n",
      "1  | val_metrics                       | MetricCollection                 | 0      | train\n",
      "2  | input_embeddings                  | _MultiEmbedding                  | 0      | train\n",
      "3  | static_covariates_vsn             | _VariableSelectionNetwork        | 5.0 K  | train\n",
      "4  | encoder_vsn                       | _VariableSelectionNetwork        | 8.8 K  | train\n",
      "5  | decoder_vsn                       | _VariableSelectionNetwork        | 1.6 K  | train\n",
      "6  | static_context_grn                | _GatedResidualNetwork            | 16.8 K | train\n",
      "7  | static_context_hidden_encoder_grn | _GatedResidualNetwork            | 16.8 K | train\n",
      "8  | static_context_cell_encoder_grn   | _GatedResidualNetwork            | 16.8 K | train\n",
      "9  | static_context_enrichment         | _GatedResidualNetwork            | 16.8 K | train\n",
      "10 | lstm_encoder                      | LSTM                             | 33.3 K | train\n",
      "11 | lstm_decoder                      | LSTM                             | 33.3 K | train\n",
      "12 | post_lstm_gan                     | _GateAddNorm                     | 8.4 K  | train\n",
      "13 | static_enrichment_grn             | _GatedResidualNetwork            | 20.9 K | train\n",
      "14 | multihead_attn                    | _InterpretableMultiHeadAttention | 10.4 K | train\n",
      "15 | post_attn_gan                     | _GateAddNorm                     | 8.4 K  | train\n",
      "16 | feed_forward_block                | _GatedResidualNetwork            | 16.8 K | train\n",
      "17 | pre_output_gan                    | _GateAddNorm                     | 8.4 K  | train\n",
      "18 | output_layer                      | Linear                           | 1.1 K  | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "223 K     Trainable params\n",
      "0         Non-trainable params\n",
      "223 K     Total params\n",
      "0.894     Total estimated model params size (MB)\n",
      "276       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75d227ece14044cb833908fa1f5b1788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0ea017d38ad4f7d99266b314f39106a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb2f80706b36474990d49cfc7ef09b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "785c347ae2df4b0d89e8321d0e00c262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3159a808353e459e930b2913eb050e2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8669eba1de546d88b9cc1ccf2cb42f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ebabbe98b241849194cddb9cce0a43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cef22230b494c55a0b2a46f12e9566b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94430a88555a4e9da582cea1d5aad20b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd94d1f5a0544c0959417a89cf93eff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6291369af44c4f80adacdebb87f28283",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2477bcbfddd8461b9a49d9454929756b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a88a2bcdcbf409c9e26b91c94487d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e2b11dc49324c2bab4c86f1b2a82732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7230c828c45849db88ae3ac61f2bf6ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01b49220a7a14de5ba4a2b3a0a46146b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f529a8a48db4468a9c12738df34ca79a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b647414ec4ba402089f8a3a266df4056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f366396bb04fbba79c4addfe5d9463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4f90609a1614a23a47732fd9687558e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be4c9ccc610d4f9993b82bd879f2f814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f3fd15b5454a89839bac5e87c95c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d3942bec5d0472eb30bb5a7ffaeec5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67190c5218564a57916c2afde7c4ca80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3729fe46c3894bcea88648b68523cc32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeadedda973f48448c2c46a8afebc13f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469f5a26ec934be1a26f58841dde6eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "172eaa6ad0284a9b89ed1a86dc9ad4c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b1cecba8c6495f8a271ed7f5cb108a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d68c436b6e224c199fdfb99c1878cd01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f5b73de7c0f440c960c0e6bf350c235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41013a5a563b46f78d7c0f225ea393d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Loading best checkpoint (A′) ===\n",
      "Loaded best checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Rolling non-overlap (Scenario A′, POOLED, TEST) ===\n",
      "windows=9 | step=24 | each window predicts H=24 | points=36\n",
      "RMSE: 1.3151192665100098\n",
      "MAE : 1.0493006706237793\n",
      "\n",
      "=== P50 q-risk (Scenario A′, ROLLING, TEST) ===\n",
      "scaled  : 0.8783319582725576\n",
      "unscaled: 0.01524196729964689\n",
      "\n",
      "=== Plotting 2 figs per grid point (Scenario A′) ===\n",
      "Saved 2 figs/point for 36 points under: /home/wangxc1117/TFTModel-use/geospatial-neural-adapter-dev/examples/try/simulation/TFT_simulation_A1/TFT_plots_synth_tft_Aprime_2figs\n",
      "\n",
      "All done (Scenario A′: linear world, eta_rho=0.6).\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.models import TFTModel\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "from geospatial_neural_adapter.data.preprocessing import prepare_all_with_scaling\n",
    "from geospatial_neural_adapter.data.generators import generate_time_synthetic_data\n",
    "\n",
    "\n",
    "# Global settings & experiment dirs\n",
    "GLOBAL_SEED = 42\n",
    "np.random.seed(GLOBAL_SEED)\n",
    "torch.manual_seed(GLOBAL_SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "try:\n",
    "    EXP_ROOT = Path(__file__).resolve().parent\n",
    "except NameError:\n",
    "    EXP_ROOT = Path.cwd()\n",
    "\n",
    "CKPT_DIR = (EXP_ROOT / \"darts_ckpt_synth_tft_Aprime\").resolve()\n",
    "RUNS_DIR = (EXP_ROOT / \"TFT_runs_synth_tft_Aprime\").resolve()\n",
    "PLOTS_DIR = (EXP_ROOT / \"TFT_plots_synth_tft_Aprime_2figs\").resolve()\n",
    "\n",
    "CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RUNS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# Generate synthetic data\n",
    "N_POINTS = 36\n",
    "T_TOTAL = 1500\n",
    "EIGENVALUE = 3.0\n",
    "\n",
    "locs = np.linspace(-5.0, 5.0, N_POINTS).astype(np.float32)\n",
    "\n",
    "cat_synth, cont_synth, y_synth = generate_time_synthetic_data(\n",
    "    locs=locs,\n",
    "    n_time_steps=T_TOTAL,\n",
    "    noise_std=0.3,\n",
    "    eigenvalue=EIGENVALUE,\n",
    "    eta_rho=0.6,\n",
    "    f_rho=0.6,\n",
    "    global_mean=50.0,\n",
    "    feature_noise_std=0.0,\n",
    "    non_linear_strength=0.0,\n",
    "    seed=GLOBAL_SEED,\n",
    ")\n",
    "\n",
    "print(\"Synthetic (A′) y shape:\", y_synth.shape)\n",
    "print(\"Synthetic (A′) cont shape:\", cont_synth.shape)\n",
    "\n",
    "Y = y_synth.astype(np.float32)\n",
    "X = cont_synth.astype(np.float32)\n",
    "\n",
    "T_total, N = Y.shape\n",
    "_, _, P_time = X.shape\n",
    "\n",
    "time_start = pd.Timestamp(\"2000-01-01 00:00:00\")\n",
    "time_index = pd.date_range(start=time_start, periods=T_total, freq=\"1H\")\n",
    "freq = \"1H\"\n",
    "if len(time_index) != T_total:\n",
    "    raise RuntimeError(\"Global time_index length mismatch.\")\n",
    "\n",
    "print(\"Total time steps:\", T_total)\n",
    "print(\"Number of points:\", N)\n",
    "print(\"Freq:\", freq)\n",
    "\n",
    "PAST_COV_COLS = [\"f1\", \"f2\", \"f3\"]\n",
    "\n",
    "cat_dummy = np.zeros((T_total, N, 1), dtype=np.int64)\n",
    "\n",
    "\n",
    "# Train/Val/Test split + pooled scaling\n",
    "train_ratio = 0.70\n",
    "val_ratio = 0.15\n",
    "\n",
    "cut_train = int(T_total * train_ratio)\n",
    "cut_val = int(T_total * (train_ratio + val_ratio))\n",
    "if not (0 < cut_train < cut_val < T_total):\n",
    "    raise ValueError(\"Bad split indices computed from ratios.\")\n",
    "\n",
    "print(\"\\n=== Split (by time index) [Scenario A′] ===\")\n",
    "print(\"Train:\", 0, \"->\", cut_train - 1, \"| len =\", cut_train)\n",
    "print(\"Val  :\", cut_train, \"->\", cut_val - 1, \"| len =\", cut_val - cut_train)\n",
    "print(\"Test :\", cut_val, \"->\", T_total - 1, \"| len =\", T_total - cut_val)\n",
    "\n",
    "train_ds, val_ds, test_ds, preprocessor = prepare_all_with_scaling(\n",
    "    cat_features=cat_dummy,\n",
    "    cont_features=X,\n",
    "    targets=Y,\n",
    "    train_ratio=train_ratio,\n",
    "    val_ratio=val_ratio,\n",
    "    feature_scaler_type=\"standard\",\n",
    "    target_scaler_type=\"standard\",\n",
    "    fit_on_train_only=True,\n",
    ")\n",
    "\n",
    "\n",
    "def stitch_targets(dsets) -> np.ndarray:\n",
    "    return np.concatenate(\n",
    "        [ds.tensors[2].detach().cpu().numpy().astype(np.float32) for ds in dsets],\n",
    "        axis=0,\n",
    "    )\n",
    "\n",
    "\n",
    "def stitch_cont_features(dsets) -> np.ndarray:\n",
    "    return np.concatenate(\n",
    "        [ds.tensors[1].detach().cpu().numpy().astype(np.float32) for ds in dsets],\n",
    "        axis=0,\n",
    "    )\n",
    "\n",
    "\n",
    "Y_scaled = stitch_targets([train_ds, val_ds, test_ds])\n",
    "X_scaled = stitch_cont_features([train_ds, val_ds, test_ds])\n",
    "\n",
    "if Y_scaled.shape != Y.shape:\n",
    "    raise ValueError(f\"Y_scaled shape {Y_scaled.shape} != Y {Y.shape}\")\n",
    "if X_scaled.shape != X.shape:\n",
    "    raise ValueError(f\"X_scaled shape {X_scaled.shape} != X {X.shape}\")\n",
    "\n",
    "print(\"\\n=== After pooled scaling (train-only, A′) ===\")\n",
    "print(\"Y_scaled:\", Y_scaled.shape, \"| finite:\", bool(np.isfinite(Y_scaled).all()))\n",
    "print(\"X_scaled:\", X_scaled.shape, \"| finite:\", bool(np.isfinite(X_scaled).all()))\n",
    "\n",
    "\n",
    "# Build TimeSeries lists\n",
    "from typing import List as _ListTs\n",
    "\n",
    "series_all: _ListTs[TimeSeries] = []\n",
    "pcov_all: _ListTs[TimeSeries] = []\n",
    "\n",
    "K_LAT = 6\n",
    "K_LON = 6\n",
    "if K_LAT * K_LON != N:\n",
    "    lat_pts = np.linspace(-5.0, 5.0, N).astype(np.float32)\n",
    "    lon_pts = np.zeros_like(lat_pts, dtype=np.float32)\n",
    "else:\n",
    "    lat_lin = np.linspace(18.0, 53.6, K_LAT, dtype=np.float32)\n",
    "    lon_lin = np.linspace(73.5, 134.8, K_LON, dtype=np.float32)\n",
    "    lat_grid, lon_grid = np.meshgrid(lat_lin, lon_lin, indexing=\"ij\")\n",
    "    lat_pts = lat_grid.reshape(-1).astype(np.float32)\n",
    "    lon_pts = lon_grid.reshape(-1).astype(np.float32)\n",
    "\n",
    "alt_pts = np.zeros_like(lat_pts, dtype=np.float32)\n",
    "\n",
    "for j in range(N):\n",
    "    name = f\"grid_{j:03d}\"\n",
    "\n",
    "    ts = TimeSeries.from_times_and_values(\n",
    "        times=time_index,\n",
    "        values=Y_scaled[:, j:j + 1].astype(np.float32),\n",
    "        columns=[name],\n",
    "        freq=freq,\n",
    "    )\n",
    "\n",
    "    lat_s = float(lat_pts[j])\n",
    "    lon_s = float(lon_pts[j])\n",
    "    alt_s = float(alt_pts[j])\n",
    "    sc = pd.DataFrame(\n",
    "        {\"lat\": [lat_s], \"lon\": [lon_s], \"alt\": [alt_s]},\n",
    "        index=[name],\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "\n",
    "    ts = ts.with_static_covariates(sc)\n",
    "    series_all.append(ts)\n",
    "\n",
    "    pc = TimeSeries.from_times_and_values(\n",
    "        times=time_index,\n",
    "        values=X_scaled[:, j, :].astype(np.float32),\n",
    "        columns=[f\"{name}_{c}\" for c in PAST_COV_COLS],\n",
    "        freq=freq,\n",
    "    ).with_static_covariates(sc)\n",
    "\n",
    "    pcov_all.append(pc)\n",
    "\n",
    "print(\"\\nBuilt TimeSeries (Scenario A′):\")\n",
    "print(\"Targets:\", len(series_all))\n",
    "print(\"Past covs:\", len(pcov_all))\n",
    "\n",
    "\n",
    "# Internal validation\n",
    "L, H = 56, 24\n",
    "INTERNAL_VAL_STEPS = 240\n",
    "\n",
    "\n",
    "def slice_list(xs, a, b):\n",
    "    return [x[a:b] for x in xs]\n",
    "\n",
    "\n",
    "train_series = slice_list(series_all, 0, cut_train)\n",
    "train_pcov = slice_list(pcov_all, 0, cut_train)\n",
    "\n",
    "iv_start = max(0, cut_train - INTERNAL_VAL_STEPS)\n",
    "iv_end = cut_train\n",
    "\n",
    "min_needed = L + H\n",
    "if (iv_end - iv_start) < min_needed:\n",
    "    iv_start = max(0, iv_end - min_needed)\n",
    "\n",
    "val_series = slice_list(series_all, iv_start, iv_end)\n",
    "val_pcov = slice_list(pcov_all, iv_start, iv_end)\n",
    "\n",
    "print(\"\\n=== INTERNAL validation (A′, for early stopping only) ===\")\n",
    "print(\"Train len:\", len(train_series[0]))\n",
    "print(\"IntVal idx:\", iv_start, \"->\", iv_end - 1, \"| len =\", len(val_series[0]))\n",
    "print(\"IntVal time:\", time_index[iv_start], \"->\", time_index[iv_end - 1])\n",
    "\n",
    "\n",
    "# Train TFT\n",
    "MODEL_NAME = f\"tft_synth_Aprime_L{L}_H{H}_seed{GLOBAL_SEED}\"\n",
    "LOG_ROOT = (RUNS_DIR / f\"seed_{GLOBAL_SEED}\").resolve()\n",
    "LOG_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "tft = TFTModel(\n",
    "    input_chunk_length=L,\n",
    "    output_chunk_length=H,\n",
    "    n_epochs=30,\n",
    "    hidden_size=64,\n",
    "    num_attention_heads=4,\n",
    "    dropout=0.1,\n",
    "    batch_size=32,\n",
    "    optimizer_kwargs={\"lr\": 3e-4},\n",
    "    add_relative_index=True,\n",
    "    random_state=GLOBAL_SEED,\n",
    "    force_reset=True,\n",
    "    model_name=MODEL_NAME,\n",
    "    work_dir=str(CKPT_DIR),\n",
    "    save_checkpoints=True,\n",
    "    pl_trainer_kwargs={\n",
    "        \"accelerator\": \"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "        \"devices\": 1,\n",
    "        \"enable_progress_bar\": True,\n",
    "        \"enable_model_summary\": False,\n",
    "        \"enable_checkpointing\": True,\n",
    "        \"callbacks\": [EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=6)],\n",
    "        \"logger\": CSVLogger(save_dir=str(LOG_ROOT), name=MODEL_NAME),\n",
    "        \"gradient_clip_val\": 1.0,\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"\\n=== Training TFT (Scenario A′: linear world, eta_rho=0.6) ===\")\n",
    "tft.fit(\n",
    "    series=train_series,\n",
    "    past_covariates=train_pcov,\n",
    "    val_series=val_series,\n",
    "    val_past_covariates=val_pcov,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"\\n=== Loading best checkpoint (A′) ===\")\n",
    "tft = TFTModel.load_from_checkpoint(model_name=MODEL_NAME, work_dir=str(CKPT_DIR), best=True)\n",
    "print(\"Loaded best checkpoint.\")\n",
    "\n",
    "\n",
    "# Rolling non-overlap over TEST\n",
    "def rolling_nonoverlap(model, series, pcov, start, end, L, H):\n",
    "    yh, yt = [], []\n",
    "    t0_list = []\n",
    "    for t0 in range(start, end - H + 1, H):\n",
    "        if t0 < L:\n",
    "            continue\n",
    "        ctx_s = [s[:t0] for s in series]\n",
    "        ctx_p = [p[:t0] for p in pcov]\n",
    "        preds = model.predict(n=H, series=ctx_s, past_covariates=ctx_p, verbose=False)\n",
    "        preds = preds if isinstance(preds, list) else [preds]\n",
    "\n",
    "        yh.append(\n",
    "            np.stack([p.values(copy=False)[:, 0] for p in preds], axis=1).astype(np.float32)\n",
    "        )\n",
    "        yt.append(\n",
    "            np.stack([s[t0:t0 + H].values(copy=False)[:, 0] for s in series], axis=1).astype(np.float32)\n",
    "        )\n",
    "        t0_list.append(int(t0))\n",
    "\n",
    "    if len(yh) == 0:\n",
    "        raise RuntimeError(\"No rolling windows produced. Check start/end/L/H.\")\n",
    "    return np.stack(yh, axis=0), np.stack(yt, axis=0), t0_list\n",
    "\n",
    "\n",
    "test_start = cut_val\n",
    "start_ctx = max(test_start, L)\n",
    "yhat_roll, ytrue_roll, t0_list = rolling_nonoverlap(\n",
    "    tft, series_all, pcov_all, start_ctx, T_total, L, H\n",
    ")\n",
    "\n",
    "W = yhat_roll.shape[0]\n",
    "print(\"\\n=== Rolling non-overlap (Scenario A′, POOLED, TEST) ===\")\n",
    "print(f\"windows={W} | step={H} | each window predicts H={H} | points={N}\")\n",
    "\n",
    "diff = yhat_roll - ytrue_roll\n",
    "rmse = float(np.sqrt(np.mean(diff ** 2)))\n",
    "mae = float(np.mean(np.abs(diff)))\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAE :\", mae)\n",
    "\n",
    "\n",
    "# P50 q-risk\n",
    "def qrisk(y_true, y_pred, q=0.5, eps=1e-8):\n",
    "    y_true = np.asarray(y_true, dtype=np.float64)\n",
    "    y_pred = np.asarray(y_pred, dtype=np.float64)\n",
    "    e = y_true - y_pred\n",
    "    return float(\n",
    "        2.0 * np.sum(np.maximum(q * e, (q - 1) * e)) / (np.sum(np.abs(y_true)) + eps)\n",
    "    )\n",
    "\n",
    "\n",
    "yhat_f = yhat_roll.reshape(-1, N)\n",
    "ytrue_f = ytrue_roll.reshape(-1, N)\n",
    "\n",
    "print(\"\\n=== P50 q-risk (Scenario A′, ROLLING, TEST) ===\")\n",
    "print(\"scaled  :\", qrisk(ytrue_f, yhat_f))\n",
    "\n",
    "ytrue_un = preprocessor.inverse_transform_targets(ytrue_f)\n",
    "yhat_un = preprocessor.inverse_transform_targets(yhat_f)\n",
    "print(\"unscaled:\", qrisk(ytrue_un, yhat_un))\n",
    "\n",
    "\n",
    "# Plot\n",
    "test_end = T_total\n",
    "test_len = test_end - test_start\n",
    "\n",
    "y_true_test = Y_scaled[test_start:test_end, :].astype(np.float32)\n",
    "\n",
    "y_pred_test = np.full((test_len, N), np.nan, dtype=np.float32)\n",
    "for w, t0 in enumerate(t0_list):\n",
    "    a = t0 - test_start\n",
    "    b = a + H\n",
    "    if a < 0 or b > test_len:\n",
    "        continue\n",
    "    y_pred_test[a:b, :] = yhat_roll[w]\n",
    "\n",
    "w0 = 0\n",
    "t0_first = t0_list[w0]\n",
    "dates_first = time_index[t0_first:t0_first + H]\n",
    "dates_test = time_index[test_start:test_end]\n",
    "\n",
    "\n",
    "def plot_two_figs_all_points(out_dir: Path):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for j in range(N):\n",
    "        point_id = j\n",
    "\n",
    "        y_true_H = ytrue_roll[w0][:, j]\n",
    "        y_pred_H = yhat_roll[w0][:, j]\n",
    "\n",
    "        plt.figure(figsize=(10, 4), dpi=140)\n",
    "        plt.plot(dates_first, y_true_H, \"-o\", linewidth=2, markersize=3, label=\"True\")\n",
    "        plt.plot(dates_first, y_pred_H, \"-o\", linewidth=2, markersize=3, label=\"Pred\")\n",
    "        plt.title(\n",
    "            f\"FIG1 Synthetic A′ | grid_{point_id:03d} | \"\n",
    "            f\"TEST first {H} steps | y (scaled)\"\n",
    "        )\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Scaled target\")\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        p1 = out_dir / f\"FIG1_grid{point_id:03d}_test_firstH{H}_t0{t0_first}.png\"\n",
    "        plt.savefig(p1)\n",
    "        plt.close()\n",
    "\n",
    "        y_true_all = y_true_test[:, j]\n",
    "        y_pred_all = y_pred_test[:, j]\n",
    "\n",
    "        plt.figure(figsize=(12, 4), dpi=140)\n",
    "        plt.plot(dates_test, y_true_all, \"-\", linewidth=1.8, label=\"True\")\n",
    "        plt.plot(\n",
    "            dates_test,\n",
    "            y_pred_all,\n",
    "            \"-\",\n",
    "            linewidth=1.8,\n",
    "            label=\"Pred (stitched rolling)\",\n",
    "        )\n",
    "        plt.axvline(time_index[test_start], linestyle=\"--\", linewidth=1, label=\"TEST start\")\n",
    "        plt.title(\n",
    "            f\"FIG2 Synthetic A′ | grid_{point_id:03d} | \"\n",
    "            f\"ALL TEST | y (scaled)\"\n",
    "        )\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Scaled target\")\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        p2 = out_dir / f\"FIG2_grid{point_id:03d}_test_all_stitched_step{H}.png\"\n",
    "        plt.savefig(p2)\n",
    "        plt.close()\n",
    "\n",
    "    print(f\"Saved 2 figs/point for {N} points under: {out_dir}\")\n",
    "\n",
    "\n",
    "print(\"\\n=== Plotting 2 figs per grid point (Scenario A′) ===\")\n",
    "plot_two_figs_all_points(PLOTS_DIR)\n",
    "\n",
    "print(\"\\nAll done.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial-neural-adapter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
