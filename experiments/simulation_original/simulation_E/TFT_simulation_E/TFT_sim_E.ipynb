{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb75176b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangxc1117/miniconda3/envs/geospatial-neural-adapter/lib/python3.10/site-packages/fs/__init__.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)  # type: ignore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded spatial_utils from: /home/wangxc1117/geospatial-neural-adapter/geospatial_neural_adapter/cpp_extensions/spatial_utils.so\n",
      "Device: cuda\n",
      "Synthetic (Scenario E) y shape : (1500, 36)\n",
      "Synthetic (Scenario E) cont shape: (1500, 36, 3)\n",
      "Total time steps: 1500\n",
      "Number of points: 36\n",
      "Freq: 1H\n",
      "\n",
      "=== Split (Scenario E, by time index) ===\n",
      "Train: 0 -> 1049 | len = 1050\n",
      "Val  : 1050 -> 1274 | len = 225\n",
      "Test : 1275 -> 1499 | len = 225\n",
      "\n",
      "=== After pooled scaling (Scenario E, train-only) ===\n",
      "Y_scaled: (1500, 36) | finite: True\n",
      "X_scaled: (1500, 36, 3) | finite: True\n",
      "\n",
      "Built TimeSeries (Scenario E):\n",
      "Targets: 36\n",
      "Past covs: 36\n",
      "\n",
      "=== INTERNAL validation (Scenario E, for early stopping only) ===\n",
      "Train len: 1050\n",
      "IntVal idx: 810 -> 1049 | len = 240\n",
      "IntVal time: 2000-02-03 18:00:00 -> 2000-02-13 17:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training TFT (Scenario E: strong nonlinear, weak AR, high cov memory) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                              | Type                             | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | train_metrics                     | MetricCollection                 | 0      | train\n",
      "1  | val_metrics                       | MetricCollection                 | 0      | train\n",
      "2  | input_embeddings                  | _MultiEmbedding                  | 0      | train\n",
      "3  | static_covariates_vsn             | _VariableSelectionNetwork        | 5.0 K  | train\n",
      "4  | encoder_vsn                       | _VariableSelectionNetwork        | 8.8 K  | train\n",
      "5  | decoder_vsn                       | _VariableSelectionNetwork        | 1.6 K  | train\n",
      "6  | static_context_grn                | _GatedResidualNetwork            | 16.8 K | train\n",
      "7  | static_context_hidden_encoder_grn | _GatedResidualNetwork            | 16.8 K | train\n",
      "8  | static_context_cell_encoder_grn   | _GatedResidualNetwork            | 16.8 K | train\n",
      "9  | static_context_enrichment         | _GatedResidualNetwork            | 16.8 K | train\n",
      "10 | lstm_encoder                      | LSTM                             | 33.3 K | train\n",
      "11 | lstm_decoder                      | LSTM                             | 33.3 K | train\n",
      "12 | post_lstm_gan                     | _GateAddNorm                     | 8.4 K  | train\n",
      "13 | static_enrichment_grn             | _GatedResidualNetwork            | 20.9 K | train\n",
      "14 | multihead_attn                    | _InterpretableMultiHeadAttention | 10.4 K | train\n",
      "15 | post_attn_gan                     | _GateAddNorm                     | 8.4 K  | train\n",
      "16 | feed_forward_block                | _GatedResidualNetwork            | 16.8 K | train\n",
      "17 | pre_output_gan                    | _GateAddNorm                     | 8.4 K  | train\n",
      "18 | output_layer                      | Linear                           | 1.1 K  | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "223 K     Trainable params\n",
      "0         Non-trainable params\n",
      "223 K     Total params\n",
      "0.894     Total estimated model params size (MB)\n",
      "276       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfcb352c2c774520a02d88f82dce05e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de4ea00c32984479a09ec75042ed2245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a6384712ba479194e315f6a73468d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2101c9b5edbd494cb3adf7745e73a711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f62634a62b634d398de68158dd4f7997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "987a32b061b440ccbc5f28bfccb93df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ed8b3d2e7440989168eed2c13cf31c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd0e2c04de7438290a0bbd4d2cef3c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1102dec3d3764c1e88c010cbd6f6459a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01d82f36c73945ca94b5a0971fb0ef3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a63f13e9805b4f39b11a5295290d3ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3bd7b6c39b7457080d58fd2e47bc6bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f92aa83f418b4eba94576b8d85b48799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1079bc27764e6eb71cf694c908d916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa691f07c9fe468c9c238e37a64fc396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e234cf88514da79286c7f6f3a16564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c87bf7cb88714b8c98691f43b13ac95e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b192eba218f343c0a731fcebc58b8a96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d5a50cc20b49e0937742eb4a0da991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ed795ffecd94623b23b41b252e4428e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a325c1bba3e5458390946c46817138ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e7ef2a346e430f8f1d6744c2fec9e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d53a52432bf4d3da1ddb41bf8480e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24fd5fddd45d4750a62c37b1f1ad9e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78bb98e049d74e48a5ed08692b28bff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "358918d61652471c926ae8e23246fbb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c51e7995a5146d2a73eafb823182641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8766dc269ea74c4c8a8911b834e3ba8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33a69e3df5ee4b108c69d345e15f5348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c6f6a4d7234c309e0ded7168f67f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "227fed06aaa444fd8defa07c30998444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0122953c5fda4eacb7f23e8304803eb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Loading best checkpoint (Scenario E) ===\n",
      "Loaded best checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Rolling non-overlap (Scenario E, POOLED, TEST) ===\n",
      "windows=9 | step=24 | each window predicts H=24 | points=36\n",
      "RMSE: 2.284651041030884\n",
      "MAE : 1.6016075611114502\n",
      "\n",
      "=== P50 q-risk (Scenario E, ROLLING, TEST) ===\n",
      "scaled  : 1.024386723062429\n",
      "unscaled: 0.1802289015080059\n",
      "\n",
      "=== Plotting 2 figs per grid point (Scenario E) ===\n",
      "Saved 2 figs/point for 36 points under: /home/wangxc1117/TFTModel-use/geospatial-neural-adapter-dev/examples/try/simulation/TFT_simulation_E/TFT_plots_synth_tft_E_2figs\n",
      "\n",
      "All done (Scenario E, TFT baseline).\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.models import TFTModel\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "from geospatial_neural_adapter.data.preprocessing import prepare_all_with_scaling\n",
    "from geospatial_neural_adapter.data.generators import generate_time_synthetic_data\n",
    "\n",
    "\n",
    "# Global settings & dirs\n",
    "GLOBAL_SEED = 42\n",
    "np.random.seed(GLOBAL_SEED)\n",
    "torch.manual_seed(GLOBAL_SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "try:\n",
    "    EXP_ROOT = Path(__file__).resolve().parent\n",
    "except NameError:\n",
    "    EXP_ROOT = Path.cwd()\n",
    "\n",
    "CKPT_DIR = (EXP_ROOT / \"darts_ckpt_synth_tft_E\").resolve()\n",
    "RUNS_DIR = (EXP_ROOT / \"TFT_runs_synth_tft_E\").resolve()\n",
    "PLOTS_DIR = (EXP_ROOT / \"TFT_plots_synth_tft_E_2figs\").resolve()\n",
    "\n",
    "CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RUNS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# Data generation\n",
    "N_POINTS = 36\n",
    "T_TOTAL = 1500\n",
    "EIGENVALUE = 3.0\n",
    "\n",
    "locs = np.linspace(-5.0, 5.0, N_POINTS).astype(np.float32)\n",
    "\n",
    "_, cont_synth, y_synth = generate_time_synthetic_data(\n",
    "    locs=locs,\n",
    "    n_time_steps=T_TOTAL,\n",
    "    noise_std=0.5,\n",
    "    eigenvalue=EIGENVALUE,\n",
    "    eta_rho=0.4,\n",
    "    f_rho=0.8,\n",
    "    global_mean=50.0,\n",
    "    feature_noise_std=0.2,\n",
    "    non_linear_strength=2.5,\n",
    "    seed=GLOBAL_SEED,\n",
    ")\n",
    "\n",
    "Y = y_synth.astype(np.float32)\n",
    "X = cont_synth.astype(np.float32)\n",
    "\n",
    "T_total, N = Y.shape\n",
    "P_time = X.shape[2]\n",
    "\n",
    "print(\"Synthetic (Scenario E) y shape :\", Y.shape)\n",
    "print(\"Synthetic (Scenario E) cont shape:\", X.shape)\n",
    "\n",
    "time_start = pd.Timestamp(\"2000-01-01 00:00:00\")\n",
    "time_index = pd.date_range(start=time_start, periods=T_total, freq=\"1H\")\n",
    "freq = \"1H\"\n",
    "if len(time_index) != T_total:\n",
    "    raise RuntimeError(\"time_index length mismatch\")\n",
    "\n",
    "PAST_COV_COLS = [\"f1\", \"f2\", \"f3\"]\n",
    "cat_dummy = np.zeros((T_total, N, 1), dtype=np.int64)\n",
    "\n",
    "\n",
    "# Split & pooled scaling\n",
    "train_ratio = 0.70\n",
    "val_ratio = 0.15\n",
    "\n",
    "cut_train = int(T_total * train_ratio)\n",
    "cut_val = int(T_total * (train_ratio + val_ratio))\n",
    "if not (0 < cut_train < cut_val < T_total):\n",
    "    raise ValueError(\"bad split indices\")\n",
    "\n",
    "print(\"\\n=== Split (Scenario E, by time index) ===\")\n",
    "print(\"Train:\", 0, \"->\", cut_train - 1, \"| len =\", cut_train)\n",
    "print(\"Val  :\", cut_train, \"->\", cut_val - 1, \"| len =\", cut_val - cut_train)\n",
    "print(\"Test :\", cut_val, \"->\", T_total - 1, \"| len =\", T_total - cut_val)\n",
    "\n",
    "train_ds, val_ds, test_ds, preprocessor = prepare_all_with_scaling(\n",
    "    cat_features=cat_dummy,\n",
    "    cont_features=X,\n",
    "    targets=Y,\n",
    "    train_ratio=train_ratio,\n",
    "    val_ratio=val_ratio,\n",
    "    feature_scaler_type=\"standard\",\n",
    "    target_scaler_type=\"standard\",\n",
    "    fit_on_train_only=True,\n",
    ")\n",
    "\n",
    "Y_scaled = np.concatenate(\n",
    "    [ds.tensors[2].detach().cpu().numpy().astype(np.float32) for ds in (train_ds, val_ds, test_ds)],\n",
    "    axis=0,\n",
    ")\n",
    "X_scaled = np.concatenate(\n",
    "    [ds.tensors[1].detach().cpu().numpy().astype(np.float32) for ds in (train_ds, val_ds, test_ds)],\n",
    "    axis=0,\n",
    ")\n",
    "\n",
    "if Y_scaled.shape != Y.shape:\n",
    "    raise ValueError(f\"Y_scaled shape {Y_scaled.shape} != Y {Y.shape}\")\n",
    "if X_scaled.shape != X.shape:\n",
    "    raise ValueError(f\"X_scaled shape {X_scaled.shape} != X {X.shape}\")\n",
    "\n",
    "print(\"\\n=== After pooled scaling (Scenario E, train-only) ===\")\n",
    "print(\"Y_scaled:\", Y_scaled.shape, \"| finite:\", bool(np.isfinite(Y_scaled).all()))\n",
    "print(\"X_scaled:\", X_scaled.shape, \"| finite:\", bool(np.isfinite(X_scaled).all()))\n",
    "\n",
    "\n",
    "# TimeSeries build\n",
    "series_all = []\n",
    "pcov_all = []\n",
    "\n",
    "K_LAT, K_LON = 6, 6\n",
    "if K_LAT * K_LON != N:\n",
    "    lat_pts = np.linspace(-5.0, 5.0, N).astype(np.float32)\n",
    "    lon_pts = np.zeros_like(lat_pts, dtype=np.float32)\n",
    "else:\n",
    "    lat_lin = np.linspace(18.0, 53.6, K_LAT, dtype=np.float32)\n",
    "    lon_lin = np.linspace(73.5, 134.8, K_LON, dtype=np.float32)\n",
    "    lat_grid, lon_grid = np.meshgrid(lat_lin, lon_lin, indexing=\"ij\")\n",
    "    lat_pts = lat_grid.reshape(-1).astype(np.float32)\n",
    "    lon_pts = lon_grid.reshape(-1).astype(np.float32)\n",
    "\n",
    "alt_pts = np.zeros_like(lat_pts, dtype=np.float32)\n",
    "\n",
    "for j in range(N):\n",
    "    name = f\"grid_{j:03d}\"\n",
    "\n",
    "    ts = TimeSeries.from_times_and_values(\n",
    "        times=time_index,\n",
    "        values=Y_scaled[:, j:j + 1].astype(np.float32),\n",
    "        columns=[name],\n",
    "        freq=freq,\n",
    "    )\n",
    "\n",
    "    sc = pd.DataFrame(\n",
    "        {\"lat\": [float(lat_pts[j])], \"lon\": [float(lon_pts[j])], \"alt\": [float(alt_pts[j])]},\n",
    "        index=[name],\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "\n",
    "    ts = ts.with_static_covariates(sc)\n",
    "    series_all.append(ts)\n",
    "\n",
    "    pc = TimeSeries.from_times_and_values(\n",
    "        times=time_index,\n",
    "        values=X_scaled[:, j, :].astype(np.float32),\n",
    "        columns=[f\"{name}_{c}\" for c in PAST_COV_COLS],\n",
    "        freq=freq,\n",
    "    ).with_static_covariates(sc)\n",
    "\n",
    "    pcov_all.append(pc)\n",
    "\n",
    "print(\"\\nBuilt TimeSeries (Scenario E):\")\n",
    "print(\"Targets:\", len(series_all))\n",
    "print(\"Past covs:\", len(pcov_all))\n",
    "\n",
    "\n",
    "# Internal validation\n",
    "L, H = 56, 24\n",
    "INTERNAL_VAL_STEPS = 240\n",
    "\n",
    "def slice_list(xs, a, b):\n",
    "    return [x[a:b] for x in xs]\n",
    "\n",
    "train_series = slice_list(series_all, 0, cut_train)\n",
    "train_pcov = slice_list(pcov_all, 0, cut_train)\n",
    "\n",
    "iv_start = max(0, cut_train - INTERNAL_VAL_STEPS)\n",
    "iv_end = cut_train\n",
    "\n",
    "min_needed = L + H\n",
    "if (iv_end - iv_start) < min_needed:\n",
    "    iv_start = max(0, iv_end - min_needed)\n",
    "\n",
    "val_series = slice_list(series_all, iv_start, iv_end)\n",
    "val_pcov = slice_list(pcov_all, iv_start, iv_end)\n",
    "\n",
    "print(\"\\n=== INTERNAL validation (Scenario E) ===\")\n",
    "print(\"Train len:\", len(train_series[0]))\n",
    "print(\"IntVal idx:\", iv_start, \"->\", iv_end - 1, \"| len =\", len(val_series[0]))\n",
    "print(\"IntVal time:\", time_index[iv_start], \"->\", time_index[iv_end - 1])\n",
    "\n",
    "\n",
    "# TFT training\n",
    "MODEL_NAME = f\"tft_synth_E_L{L}_H{H}_seed{GLOBAL_SEED}\"\n",
    "LOG_ROOT = (RUNS_DIR / f\"seed_{GLOBAL_SEED}\").resolve()\n",
    "LOG_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "tft = TFTModel(\n",
    "    input_chunk_length=L,\n",
    "    output_chunk_length=H,\n",
    "    n_epochs=30,\n",
    "    hidden_size=64,\n",
    "    num_attention_heads=4,\n",
    "    dropout=0.1,\n",
    "    batch_size=32,\n",
    "    optimizer_kwargs={\"lr\": 3e-4},\n",
    "    add_relative_index=True,\n",
    "    random_state=GLOBAL_SEED,\n",
    "    force_reset=True,\n",
    "    model_name=MODEL_NAME,\n",
    "    work_dir=str(CKPT_DIR),\n",
    "    save_checkpoints=True,\n",
    "    pl_trainer_kwargs={\n",
    "        \"accelerator\": \"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "        \"devices\": 1,\n",
    "        \"enable_progress_bar\": True,\n",
    "        \"enable_model_summary\": False,\n",
    "        \"enable_checkpointing\": True,\n",
    "        \"callbacks\": [EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=6)],\n",
    "        \"logger\": CSVLogger(save_dir=str(LOG_ROOT), name=MODEL_NAME),\n",
    "        \"gradient_clip_val\": 1.0,\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"\\n=== Training TFT (Scenario E) ===\")\n",
    "tft.fit(\n",
    "    series=train_series,\n",
    "    past_covariates=train_pcov,\n",
    "    val_series=val_series,\n",
    "    val_past_covariates=val_pcov,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"\\n=== Loading best checkpoint (Scenario E) ===\")\n",
    "tft = TFTModel.load_from_checkpoint(model_name=MODEL_NAME, work_dir=str(CKPT_DIR), best=True)\n",
    "print(\"Loaded best checkpoint.\")\n",
    "\n",
    "\n",
    "# Rolling evaluation\n",
    "def rolling_nonoverlap(model, series, pcov, start, end, L, H):\n",
    "    yh, yt, t0_list = [], [], []\n",
    "    for t0 in range(start, end - H + 1, H):\n",
    "        if t0 < L:\n",
    "            continue\n",
    "        ctx_s = [s[:t0] for s in series]\n",
    "        ctx_p = [p[:t0] for p in pcov]\n",
    "        preds = model.predict(n=H, series=ctx_s, past_covariates=ctx_p, verbose=False)\n",
    "        preds = preds if isinstance(preds, list) else [preds]\n",
    "\n",
    "        yh.append(np.stack([p.values(copy=False)[:, 0] for p in preds], axis=1).astype(np.float32))\n",
    "        yt.append(np.stack([s[t0:t0 + H].values(copy=False)[:, 0] for s in series], axis=1).astype(np.float32))\n",
    "        t0_list.append(int(t0))\n",
    "\n",
    "    if len(yh) == 0:\n",
    "        raise RuntimeError(\"no rolling windows produced\")\n",
    "    return np.stack(yh, axis=0), np.stack(yt, axis=0), t0_list\n",
    "\n",
    "test_start = cut_val\n",
    "start_ctx = max(test_start, L)\n",
    "yhat_roll, ytrue_roll, t0_list = rolling_nonoverlap(tft, series_all, pcov_all, start_ctx, T_total, L, H)\n",
    "\n",
    "W = yhat_roll.shape[0]\n",
    "diff = yhat_roll - ytrue_roll\n",
    "rmse = float(np.sqrt(np.mean(diff ** 2)))\n",
    "mae = float(np.mean(np.abs(diff)))\n",
    "\n",
    "print(\"\\n=== Rolling non-overlap (Scenario E, POOLED, TEST) ===\")\n",
    "print(f\"windows={W} | step={H} | each window predicts H={H} | points={N}\")\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAE :\", mae)\n",
    "\n",
    "\n",
    "# q-risk\n",
    "def qrisk(y_true, y_pred, q=0.5, eps=1e-8):\n",
    "    y_true = np.asarray(y_true, dtype=np.float64)\n",
    "    y_pred = np.asarray(y_pred, dtype=np.float64)\n",
    "    e = y_true - y_pred\n",
    "    return float(2.0 * np.sum(np.maximum(q * e, (q - 1) * e)) / (np.sum(np.abs(y_true)) + eps))\n",
    "\n",
    "yhat_f = yhat_roll.reshape(-1, N)\n",
    "ytrue_f = ytrue_roll.reshape(-1, N)\n",
    "\n",
    "print(\"\\n=== P50 q-risk (Scenario E, ROLLING, TEST) ===\")\n",
    "print(\"scaled  :\", qrisk(ytrue_f, yhat_f))\n",
    "\n",
    "ytrue_un = preprocessor.inverse_transform_targets(ytrue_f)\n",
    "yhat_un = preprocessor.inverse_transform_targets(yhat_f)\n",
    "print(\"unscaled:\", qrisk(ytrue_un, yhat_un))\n",
    "\n",
    "\n",
    "# Plots\n",
    "test_end = T_total\n",
    "test_len = test_end - test_start\n",
    "\n",
    "y_true_test = Y_scaled[test_start:test_end, :].astype(np.float32)\n",
    "y_pred_test = np.full((test_len, N), np.nan, dtype=np.float32)\n",
    "\n",
    "for w, t0 in enumerate(t0_list):\n",
    "    a = t0 - test_start\n",
    "    b = a + H\n",
    "    if a < 0 or b > test_len:\n",
    "        continue\n",
    "    y_pred_test[a:b, :] = yhat_roll[w]\n",
    "\n",
    "w0 = 0\n",
    "t0_first = t0_list[w0]\n",
    "dates_first = time_index[t0_first:t0_first + H]\n",
    "dates_test = time_index[test_start:test_end]\n",
    "\n",
    "def plot_two_figs_all_points(out_dir: Path):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for j in range(N):\n",
    "        y_true_H = ytrue_roll[w0][:, j]\n",
    "        y_pred_H = yhat_roll[w0][:, j]\n",
    "\n",
    "        plt.figure(figsize=(10, 4), dpi=140)\n",
    "        plt.plot(dates_first, y_true_H, \"-o\", linewidth=2, markersize=3, label=\"True\")\n",
    "        plt.plot(dates_first, y_pred_H, \"-o\", linewidth=2, markersize=3, label=\"Pred\")\n",
    "        plt.title(f\"FIG1 Synthetic E | grid_{j:03d} | TEST first {H} steps | y (scaled)\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Scaled target\")\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(out_dir / f\"FIG1_grid{j:03d}_E_test_firstH{H}_t0{t0_first}.png\")\n",
    "        plt.close()\n",
    "\n",
    "        y_true_all = y_true_test[:, j]\n",
    "        y_pred_all = y_pred_test[:, j]\n",
    "\n",
    "        plt.figure(figsize=(12, 4), dpi=140)\n",
    "        plt.plot(dates_test, y_true_all, \"-\", linewidth=1.8, label=\"True\")\n",
    "        plt.plot(dates_test, y_pred_all, \"-\", linewidth=1.8, label=\"Pred (stitched rolling)\")\n",
    "        plt.axvline(time_index[test_start], linestyle=\"--\", linewidth=1, label=\"TEST start\")\n",
    "        plt.title(f\"FIG2 Synthetic E | grid_{j:03d} | ALL TEST | y (scaled)\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Scaled target\")\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(out_dir / f\"FIG2_grid{j:03d}_E_test_all_stitched_step{H}.png\")\n",
    "        plt.close()\n",
    "\n",
    "    print(f\"Saved 2 figs/point for {N} points under: {out_dir}\")\n",
    "\n",
    "print(\"\\n=== Plotting 2 figs per grid point (Scenario E) ===\")\n",
    "plot_two_figs_all_points(PLOTS_DIR)\n",
    "\n",
    "print(\"\\nAll done (Scenario E, TFT baseline).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial-neural-adapter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
