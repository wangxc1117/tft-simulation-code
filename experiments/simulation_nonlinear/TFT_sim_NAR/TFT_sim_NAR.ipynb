{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb75176b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangxc1117/miniconda3/envs/geospatial-neural-adapter/lib/python3.10/site-packages/fs/__init__.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)  # type: ignore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded spatial_utils from: /home/wangxc1117/geospatial-neural-adapter/geospatial_neural_adapter/cpp_extensions/spatial_utils.so\n",
      "Device: cuda\n",
      "\n",
      "============================================================\n",
      "RUN TFT | SCENARIO=C | y_rho=0.85 | win=50 | y_gamma=0.1\n",
      "============================================================\n",
      "\n",
      "=== Scenario settings ===\n",
      "Scenario: C\n",
      "{'noise_std': 0.5, 'feature_noise_std': 0.2, 'non_linear_strength': 2.0, 'eta_rho': 0.8, 'f_rho': 0.6}\n",
      "NAR params: {'y_rho': 0.85, 'y_gamma': 0.1, 'nar_scale_window': 50, 'gate_type': 'A2_global_v2'}\n",
      "[Gate A2_global_v2] gate_ratio=0.5997 | thr=0.0 | low=0.5 | high=1.0 | win=50\n",
      "Synthetic y shape: (1500, 36)\n",
      "Synthetic cont shape: (1500, 36, 3)\n",
      "y stats (unscaled) mean/std/mean|y|: 250.49603271484375 131.10008239746094 250.49603271484375\n",
      "y_md5: 2f25135ad6de3de96dc68bab1956f95a\n",
      "\n",
      "=== Split (by time index) ===\n",
      "Train: 0 -> 1049 | len = 1050\n",
      "Val  : 1050 -> 1274 | len = 225\n",
      "Test : 1275 -> 1499 | len = 225\n",
      "\n",
      "=== After pooled scaling (train-only) ===\n",
      "Y_scaled: (1500, 36) | finite: True\n",
      "X_scaled: (1500, 36, 3) | finite: True\n",
      "\n",
      "=== INTERNAL validation (for early stopping only) ===\n",
      "Train len: 1050\n",
      "IntVal idx: 810 -> 1049 | len = 240\n",
      "IntVal time: 2000-02-03 18:00:00 -> 2000-02-13 17:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training TFT (C, NAR A2_global_v2, 1D locs, NO static) | y_gamma=0.1 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                              | Type                             | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | train_metrics                     | MetricCollection                 | 0      | train\n",
      "1  | val_metrics                       | MetricCollection                 | 0      | train\n",
      "2  | input_embeddings                  | _MultiEmbedding                  | 0      | train\n",
      "3  | static_covariates_vsn             | _VariableSelectionNetwork        | 0      | train\n",
      "4  | encoder_vsn                       | _VariableSelectionNetwork        | 8.8 K  | train\n",
      "5  | decoder_vsn                       | _VariableSelectionNetwork        | 1.6 K  | train\n",
      "6  | static_context_grn                | _GatedResidualNetwork            | 16.8 K | train\n",
      "7  | static_context_hidden_encoder_grn | _GatedResidualNetwork            | 16.8 K | train\n",
      "8  | static_context_cell_encoder_grn   | _GatedResidualNetwork            | 16.8 K | train\n",
      "9  | static_context_enrichment         | _GatedResidualNetwork            | 16.8 K | train\n",
      "10 | lstm_encoder                      | LSTM                             | 33.3 K | train\n",
      "11 | lstm_decoder                      | LSTM                             | 33.3 K | train\n",
      "12 | post_lstm_gan                     | _GateAddNorm                     | 8.4 K  | train\n",
      "13 | static_enrichment_grn             | _GatedResidualNetwork            | 20.9 K | train\n",
      "14 | multihead_attn                    | _InterpretableMultiHeadAttention | 10.4 K | train\n",
      "15 | post_attn_gan                     | _GateAddNorm                     | 8.4 K  | train\n",
      "16 | feed_forward_block                | _GatedResidualNetwork            | 16.8 K | train\n",
      "17 | pre_output_gan                    | _GateAddNorm                     | 8.4 K  | train\n",
      "18 | output_layer                      | Linear                           | 1.1 K  | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "218 K     Trainable params\n",
      "0         Non-trainable params\n",
      "218 K     Total params\n",
      "0.874     Total estimated model params size (MB)\n",
      "217       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f9da2fe240942faa202ccd7997da2d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f05eb687214c7486894096b22de7b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6afe15d493144b6592208b5679888406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c69f06bdc8c144949fecdd3d50ec7838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a66ccccc964dbf899c757daaad82da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4760ed4312e84a8f9445077745acc518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6ee809794364cbebd89f8a95d02f7f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "143e3f5811f24e379415b0ba6efe6a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e2c963a0b9a4b56a3a6d140adbf4ed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4776da98acf74a2fa984070225a94c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70f3081042ac4a48a975cd3413f69f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc909f9a0f4845ea9a7fb85248ca9f53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d10fb5ca03a472bb9a53c538cce70eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd5c293b13074e2da0763026c01b04ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa1d5bed88c4dfab7725f0d0dde59bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c007967cd3483c94be8f000d3bab10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa789ed12d984ee99610b0d15d822efa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f338af9eeac9489f8788b4939500f830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4642cb0aa5ed48d9bbf3c7fceeffd56e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f8000edb6347128547bd533eff283a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe3a8cfaafc34f6b94d3fcda8f47728d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cddf09ffa83413bb55247683b887f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02da6b19e7684b4e8a6e39029c3699e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9c2fd047aa64e0aa7d66c14c82932d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1bfd2ba33649309d2aa16d4a904d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d80e19629ab400d992e36751eb87968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "341106e8f72d4883bcafe350fcb50093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87bdafd165f84f8ca8366238f9e24ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c8054d74054e39956719dcdef16aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa3b122c3d7474d9ba4e225ee956118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b698deec411f4e87a4cd3c82bc8418ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d12478804e84c208582e7fa7e84dfbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Loading best checkpoint ===\n",
      "Loaded best checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Rolling non-overlap (POOLED, TEST) ===\n",
      "windows=9 | step=24 | each window predicts H=24 | points=36\n",
      "RMSE: 0.6261568665504456\n",
      "MAE : 0.3076390027999878\n",
      "\n",
      "=== P50 q-risk (ROLLING, TEST) ===\n",
      "scaled  : 0.2832062245992567\n",
      "unscaled: 0.15747766019815884\n",
      "\n",
      "=== Plotting 2 figs per grid point | y_gamma=0.1 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2 figs/point for 36 points under: /home/wangxc1117/TFTModel-use/geospatial-neural-adapter-dev/examples/try/simulation_NAR/TFT_sim_NAR/TFT_plots_synth_tft_C_NAR_A2_global_v2_yrho0.85_win50_1D_NOSTATIC_ONLY2G_2figs/ygamma_0.1\n",
      "\n",
      "============================================================\n",
      "RUN TFT | SCENARIO=C | y_rho=0.85 | win=50 | y_gamma=0.2\n",
      "============================================================\n",
      "\n",
      "=== Scenario settings ===\n",
      "Scenario: C\n",
      "{'noise_std': 0.5, 'feature_noise_std': 0.2, 'non_linear_strength': 2.0, 'eta_rho': 0.8, 'f_rho': 0.6}\n",
      "NAR params: {'y_rho': 0.85, 'y_gamma': 0.2, 'nar_scale_window': 50, 'gate_type': 'A2_global_v2'}\n",
      "[Gate A2_global_v2] gate_ratio=0.6104 | thr=0.0 | low=0.5 | high=1.0 | win=50\n",
      "Synthetic y shape: (1500, 36)\n",
      "Synthetic cont shape: (1500, 36, 3)\n",
      "y stats (unscaled) mean/std/mean|y|: 253.73133850097656 130.7637176513672 253.73133850097656\n",
      "y_md5: abec649232e0950d399c0c830544bcae\n",
      "\n",
      "=== Split (by time index) ===\n",
      "Train: 0 -> 1049 | len = 1050\n",
      "Val  : 1050 -> 1274 | len = 225\n",
      "Test : 1275 -> 1499 | len = 225\n",
      "\n",
      "=== After pooled scaling (train-only) ===\n",
      "Y_scaled: (1500, 36) | finite: True\n",
      "X_scaled: (1500, 36, 3) | finite: True\n",
      "\n",
      "=== INTERNAL validation (for early stopping only) ===\n",
      "Train len: 1050\n",
      "IntVal idx: 810 -> 1049 | len = 240\n",
      "IntVal time: 2000-02-03 18:00:00 -> 2000-02-13 17:00:00\n",
      "\n",
      "=== Training TFT (C, NAR A2_global_v2, 1D locs, NO static) | y_gamma=0.2 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                              | Type                             | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | train_metrics                     | MetricCollection                 | 0      | train\n",
      "1  | val_metrics                       | MetricCollection                 | 0      | train\n",
      "2  | input_embeddings                  | _MultiEmbedding                  | 0      | train\n",
      "3  | static_covariates_vsn             | _VariableSelectionNetwork        | 0      | train\n",
      "4  | encoder_vsn                       | _VariableSelectionNetwork        | 8.8 K  | train\n",
      "5  | decoder_vsn                       | _VariableSelectionNetwork        | 1.6 K  | train\n",
      "6  | static_context_grn                | _GatedResidualNetwork            | 16.8 K | train\n",
      "7  | static_context_hidden_encoder_grn | _GatedResidualNetwork            | 16.8 K | train\n",
      "8  | static_context_cell_encoder_grn   | _GatedResidualNetwork            | 16.8 K | train\n",
      "9  | static_context_enrichment         | _GatedResidualNetwork            | 16.8 K | train\n",
      "10 | lstm_encoder                      | LSTM                             | 33.3 K | train\n",
      "11 | lstm_decoder                      | LSTM                             | 33.3 K | train\n",
      "12 | post_lstm_gan                     | _GateAddNorm                     | 8.4 K  | train\n",
      "13 | static_enrichment_grn             | _GatedResidualNetwork            | 20.9 K | train\n",
      "14 | multihead_attn                    | _InterpretableMultiHeadAttention | 10.4 K | train\n",
      "15 | post_attn_gan                     | _GateAddNorm                     | 8.4 K  | train\n",
      "16 | feed_forward_block                | _GatedResidualNetwork            | 16.8 K | train\n",
      "17 | pre_output_gan                    | _GateAddNorm                     | 8.4 K  | train\n",
      "18 | output_layer                      | Linear                           | 1.1 K  | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "218 K     Trainable params\n",
      "0         Non-trainable params\n",
      "218 K     Total params\n",
      "0.874     Total estimated model params size (MB)\n",
      "217       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e18c513f42b4be2962cf7101b7353fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b981017dd4d4b8298ae07b06860e1b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1da565a83ac4bb5a2da77b56e7bcf8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f0410aca527459c87066c6fb1b88d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf90551331ae45ecaa0b86ab6e526348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6905b1ca5c94bf888962a88cbda624a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a386e809734c48d69e4e40e9d168479f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfbf7b20435c4e5289583c66dcf2d203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e5f4884f8af42c8a59ec209df141b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d876f02be42d4717bc62c9dcb767aa28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90fec97717544335bf0801c6c4b188d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a9972e63ffb4ea2932308425a4e0371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c84a1d2d7d334a25b257d6f81a200c36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc80c866e384b5d8028071a3ffd78b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9c9b07e820c4fc9bb63f711255425e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ae80de42514c50ae88a789c8b1b9d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b89dee5a11247939d786acf8e23ce7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d540bc685c004f088ea3465690af4e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92cb8b9e42841518364d6dd3c48873e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0f5caeda36b4f2d8a0f08dd67f3c6f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a414e33112434af1b8f09b38c9cf5e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3276755c092a400db8f9458006fcbb0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2087c7ced183441580887afce6988864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b281d4826f4b1ebe774b37974824be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "390b3e5933cc4af1a93db4d4d0f46e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab473a81a7d44cc0a2d9e2337948c993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44b026d2e02542b3be15c0f2663d50a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1387cab99e794ec39163dfe5444e48aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51628d7d20784414b92db55075397dd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7342c703ab364f29b98202f002c8e0e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5f6d99f7eb54007811d1ba1719e3031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef60bffe2ff46c39f8784641056123d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Loading best checkpoint ===\n",
      "Loaded best checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Rolling non-overlap (POOLED, TEST) ===\n",
      "windows=9 | step=24 | each window predicts H=24 | points=36\n",
      "RMSE: 0.6630433797836304\n",
      "MAE : 0.32352277636528015\n",
      "\n",
      "=== P50 q-risk (ROLLING, TEST) ===\n",
      "scaled  : 0.29601073214743967\n",
      "unscaled: 0.16485052854802\n",
      "\n",
      "=== Plotting 2 figs per grid point | y_gamma=0.2 ===\n",
      "Saved 2 figs/point for 36 points under: /home/wangxc1117/TFTModel-use/geospatial-neural-adapter-dev/examples/try/simulation_NAR/TFT_sim_NAR/TFT_plots_synth_tft_C_NAR_A2_global_v2_yrho0.85_win50_1D_NOSTATIC_ONLY2G_2figs/ygamma_0.2\n",
      "\n",
      "================================================================================\n",
      "DONE. Saved TFT summary (2 rows) to:\n",
      "/home/wangxc1117/TFTModel-use/geospatial-neural-adapter-dev/examples/try/simulation_NAR/TFT_sim_NAR/TFT_results_synth_tft_C_NAR_A2_global_v2_yrho0.85_win50_1D_NOSTATIC_ONLY2G/RESULTS_TFT_NAR_ONLY2GAMMAS_C_A2_global_v2_yrho0.85_win50.csv\n",
      "================================================================================\n",
      "  scenario  noise_std  feature_noise_std  non_linear_strength  eta_rho  f_rho  \\\n",
      "0        C        0.5                0.2                  2.0      0.8    0.6   \n",
      "1        C        0.5                0.2                  2.0      0.8    0.6   \n",
      "\n",
      "   y_rho  y_gamma  nar_scale_window     gate_type  ...  windows   L   H  \\\n",
      "0   0.85      0.1                50  A2_global_v2  ...        9  56  24   \n",
      "1   0.85      0.2                50  A2_global_v2  ...        9  56  24   \n",
      "\n",
      "  T_total  N_points  eigenvalue  global_seed  \\\n",
      "0    1500        36         3.0           42   \n",
      "1    1500        36         3.0           42   \n",
      "\n",
      "                                             exp_tag  \\\n",
      "0  synth_tft_C_NAR_A2_global_v2_yrho0.85_win50_1D...   \n",
      "1  synth_tft_C_NAR_A2_global_v2_yrho0.85_win50_1D...   \n",
      "\n",
      "                                           plots_dir  \\\n",
      "0  /home/wangxc1117/TFTModel-use/geospatial-neura...   \n",
      "1  /home/wangxc1117/TFTModel-use/geospatial-neura...   \n",
      "\n",
      "                                            ckpt_dir  \n",
      "0  /home/wangxc1117/TFTModel-use/geospatial-neura...  \n",
      "1  /home/wangxc1117/TFTModel-use/geospatial-neura...  \n",
      "\n",
      "[2 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# ============================================================\n",
    "# Synthetic spatio-temporal data + TFT baseline (Darts)\n",
    "# [NAR(1) DGP | 1D locs | Gate A2_global_v2 centered | NO static cov | ONLY 2 GAMMAS]\n",
    "#\n",
    "# - Data: generate_time_NAR_synthetic_data (A2_global_v2, centered by rolling mean)  <-- SAME AS OLS\n",
    "# - Locations: 1D synthetic locations (N points)\n",
    "# - Target: y (T, N), multi-site\n",
    "# - Dynamic covariates: synthetic features (f1, f2, f3) as past covariates\n",
    "# - Static covariates: NONE\n",
    "# - Scaling: POOLED (train-only) via prepare_all_with_scaling (targets scaled train-only)\n",
    "# - Train/Val/Test: time split (70/15/15)\n",
    "# - Early stopping: INTERNAL validation (tail of train)\n",
    "# - Evaluation: Rolling non-overlap over TEST (step=H)\n",
    "# - Metrics: RMSE/MAE + P50 q-risk (scaled/unscaled)\n",
    "# - Runs ONLY 2 settings:\n",
    "#     (y_rho=0.85, win=50, y_gamma=0.10) and (y_rho=0.85, win=50, y_gamma=0.20)\n",
    "# - Plots (ALL grid points, 2 figs/point):\n",
    "#     FIG1: TEST first H steps (first rolling window)\n",
    "#     FIG2: ALL TEST (stitched rolling predictions)\n",
    "# - Saves summary CSV with 2 rows (one per gamma)\n",
    "#\n",
    "# IMPORTANT:\n",
    "# - This script prints y_md5 (hash) so you can verify the TFT run uses EXACTLY the same y\n",
    "#   as your OLS/VAR/VARX scripts under identical parameters + seed.\n",
    "# ============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Optional, Dict, Any\n",
    "\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.models import TFTModel\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "from geospatial_neural_adapter.data.preprocessing import prepare_all_with_scaling\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 0) Utilities\n",
    "# ============================================================\n",
    "def qrisk(y_true, y_pred, q=0.5, eps=1e-8) -> float:\n",
    "    y_true = np.asarray(y_true, dtype=np.float64)\n",
    "    y_pred = np.asarray(y_pred, dtype=np.float64)\n",
    "    e = y_true - y_pred\n",
    "    return float(\n",
    "        2.0 * np.sum(np.maximum(q * e, (q - 1) * e)) / (np.sum(np.abs(y_true)) + eps)\n",
    "    )\n",
    "\n",
    "\n",
    "def rolling_nonoverlap(model, series, pcov, start, end, L, H):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      yhat_roll: (W, H, N)\n",
    "      ytrue_roll:(W, H, N)\n",
    "      t0_list: list of window start indices\n",
    "    \"\"\"\n",
    "    yh, yt = [], []\n",
    "    t0_list = []\n",
    "    for t0 in range(start, end - H + 1, H):\n",
    "        if t0 < L:\n",
    "            continue\n",
    "\n",
    "        ctx_s = [s[:t0] for s in series]\n",
    "        ctx_p = [p[:t0] for p in pcov]\n",
    "\n",
    "        preds = model.predict(\n",
    "            n=H,\n",
    "            series=ctx_s,\n",
    "            past_covariates=ctx_p,\n",
    "            verbose=False,\n",
    "        )\n",
    "        preds = preds if isinstance(preds, list) else [preds]\n",
    "\n",
    "        yh.append(\n",
    "            np.stack([p.values(copy=False)[:, 0] for p in preds], axis=1).astype(np.float32)\n",
    "        )  # (H, N)\n",
    "        yt.append(\n",
    "            np.stack([s[t0:t0 + H].values(copy=False)[:, 0] for s in series], axis=1).astype(np.float32)\n",
    "        )  # (H, N)\n",
    "        t0_list.append(int(t0))\n",
    "\n",
    "    if len(yh) == 0:\n",
    "        raise RuntimeError(\"No rolling windows produced. Check start/end/L/H.\")\n",
    "    return np.stack(yh, axis=0), np.stack(yt, axis=0), t0_list\n",
    "\n",
    "\n",
    "def plot_two_figs_all_points(\n",
    "    out_dir: Path,\n",
    "    *,\n",
    "    exp_tag: str,\n",
    "    scenario_key: str,\n",
    "    N: int,\n",
    "    H: int,\n",
    "    w0: int,\n",
    "    t0_first: int,\n",
    "    time_index: pd.DatetimeIndex,\n",
    "    test_start: int,\n",
    "    test_end: int,\n",
    "    ytrue_roll: np.ndarray,   # (W,H,N) scaled\n",
    "    yhat_roll: np.ndarray,    # (W,H,N) scaled\n",
    "    Y_scaled: np.ndarray,     # (T,N) scaled\n",
    "    t0_list: List[int],\n",
    "):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    dates_first = time_index[t0_first:t0_first + H]\n",
    "    dates_test = time_index[test_start:test_end]\n",
    "\n",
    "    test_len = test_end - test_start\n",
    "    y_true_test = Y_scaled[test_start:test_end, :].astype(np.float32)  # (test_len, N)\n",
    "\n",
    "    y_pred_test = np.full((test_len, N), np.nan, dtype=np.float32)\n",
    "    for w, t0 in enumerate(t0_list):\n",
    "        a = t0 - test_start\n",
    "        b = a + H\n",
    "        if a < 0 or b > test_len:\n",
    "            continue\n",
    "        y_pred_test[a:b, :] = yhat_roll[w]\n",
    "\n",
    "    for j in range(N):\n",
    "        point_id = j\n",
    "\n",
    "        # FIG1: first rolling window, H steps\n",
    "        y_true_H = ytrue_roll[w0][:, j]\n",
    "        y_pred_H = yhat_roll[w0][:, j]\n",
    "\n",
    "        plt.figure(figsize=(10, 4), dpi=140)\n",
    "        plt.plot(dates_first, y_true_H, \"-o\", linewidth=2, markersize=3, label=\"True\")\n",
    "        plt.plot(dates_first, y_pred_H, \"-o\", linewidth=2, markersize=3, label=\"Pred\")\n",
    "        plt.title(\n",
    "            f\"FIG1 {scenario_key} | NAR(1) A2_global_v2 | grid_{point_id:03d} | \"\n",
    "            f\"TEST first {H} steps | y (scaled)\"\n",
    "        )\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Scaled target\")\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        p1 = out_dir / f\"FIG1_{exp_tag}_grid{point_id:03d}_test_firstH{H}_t0{t0_first}.png\"\n",
    "        plt.savefig(p1)\n",
    "        plt.close()\n",
    "\n",
    "        # FIG2: all TEST (stitched rolling predictions)\n",
    "        y_true_all = y_true_test[:, j]\n",
    "        y_pred_all = y_pred_test[:, j]\n",
    "\n",
    "        plt.figure(figsize=(12, 4), dpi=140)\n",
    "        plt.plot(dates_test, y_true_all, \"-\", linewidth=1.8, label=\"True\")\n",
    "        plt.plot(dates_test, y_pred_all, \"-\", linewidth=1.8, label=\"Pred (stitched rolling)\")\n",
    "        plt.axvline(time_index[test_start], linestyle=\"--\", linewidth=1, label=\"TEST start\")\n",
    "        plt.title(\n",
    "            f\"FIG2 {scenario_key} | NAR(1) A2_global_v2 | grid_{point_id:03d} | ALL TEST | y (scaled)\"\n",
    "        )\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Scaled target\")\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        p2 = out_dir / f\"FIG2_{exp_tag}_grid{point_id:03d}_test_all_stitched_step{H}.png\"\n",
    "        plt.savefig(p2)\n",
    "        plt.close()\n",
    "\n",
    "    print(f\"Saved 2 figs/point for {N} points under: {out_dir}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1) NAR generator (COPY FROM YOUR OLS SCRIPT)  <<<<<<<< IMPORTANT\n",
    "# ============================================================\n",
    "def _generate_spatial_basis(locations: np.ndarray) -> np.ndarray:\n",
    "    spatial_basis = np.exp(-(locations**2))[:, None]\n",
    "    spatial_basis /= (np.linalg.norm(spatial_basis) + 1e-12)\n",
    "    return spatial_basis\n",
    "\n",
    "\n",
    "def generate_time_NAR_synthetic_data(\n",
    "    locs: np.ndarray,\n",
    "    n_time_steps: int,\n",
    "    noise_std: float,\n",
    "    eigenvalue: float,\n",
    "    eta_rho: float = 0.8,\n",
    "    f_rho: float = 0.6,\n",
    "    global_mean: float = 50.0,\n",
    "    feature_noise_std: float = 0.0,\n",
    "    non_linear_strength: float = 0.0,\n",
    "    seed: Optional[int] = None,\n",
    "    y_rho: float = 0.4,\n",
    "    y_gamma: float = 1.2,\n",
    "    nar_scale_window: int = 200,\n",
    "    # ---- Gate A2 params ----\n",
    "    gate_type: str = \"A2_global_v2\",\n",
    "    gate_threshold: float = 0.0,\n",
    "    gate_low: float = 0.5,\n",
    "    gate_high: float = 1.0,\n",
    "    debug_gate_ratio: bool = True,\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Gate A2 (GLOBAL) - Version 2:\n",
    "      z_global(t) = ( mean(prev) - mean(y[w0:t]) ) / std(y[w0:t])   <-- rolling-mean centered\n",
    "      gate(t) = 1{ z_global > threshold }\n",
    "      rho_eff = y_rho * ( gate_low + (gate_high-gate_low)*gate )\n",
    "\n",
    "    NOTE:\n",
    "      - This makes gate actually flip around 0 (since centered),\n",
    "        instead of being stuck positive due to global_mean=50.\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    locs = np.asarray(locs, dtype=np.float32)\n",
    "    if locs.ndim != 1:\n",
    "        raise ValueError(f\"expects 1D locs (N,), got {locs.shape}\")\n",
    "\n",
    "    N = len(locs)\n",
    "    p = 3\n",
    "\n",
    "    cont = np.random.randn(n_time_steps, N, p).astype(np.float32)\n",
    "\n",
    "    spatial_pattern = np.sin(locs * np.pi / 5.0).astype(np.float32)\n",
    "    temporal_trend = np.linspace(0, 2 * np.pi, n_time_steps).astype(np.float32)\n",
    "\n",
    "    cont[:, :, 0] += (np.outer(temporal_trend, spatial_pattern) * 0.5).astype(np.float32)\n",
    "    cont[:, :, 1] += (np.outer(temporal_trend, np.ones(N, dtype=np.float32)) * 0.3).astype(np.float32)\n",
    "    cont[:, :, 2] += (cont[:, :, 0] * cont[:, :, 1] * 0.2).astype(np.float32)\n",
    "\n",
    "    if feature_noise_std > 0:\n",
    "        cont += (np.random.randn(*cont.shape) * feature_noise_std).astype(np.float32)\n",
    "\n",
    "    spatial_basis = _generate_spatial_basis(locs).reshape(-1).astype(np.float32)  # (N,)\n",
    "\n",
    "    spatial_weights = np.zeros(n_time_steps, dtype=np.float32)\n",
    "    trend_drift = np.zeros(n_time_steps, dtype=np.float32)\n",
    "\n",
    "    spatial_weights[0] = float(np.random.randn() * 1.0)\n",
    "    trend_drift[0] = float(np.random.randn() * 1.0)\n",
    "\n",
    "    for t in range(1, n_time_steps):\n",
    "        spatial_weights[t] = eta_rho * spatial_weights[t - 1] + float(np.random.randn() * 0.1)\n",
    "        trend_drift[t] = f_rho * trend_drift[t - 1] + float(np.random.randn() * 0.1)\n",
    "\n",
    "    y = np.zeros((n_time_steps, N), dtype=np.float32)\n",
    "    eps = 1e-6\n",
    "\n",
    "    def _feat_term(t: int) -> np.ndarray:\n",
    "        feat = (0.3 * cont[t, :, 0] + 0.4 * cont[t, :, 1] + 0.2 * cont[t, :, 2]).astype(np.float32)\n",
    "        if non_linear_strength > 0:\n",
    "            feat = (\n",
    "                feat\n",
    "                + non_linear_strength * (cont[t, :, 0] ** 2)\n",
    "                + non_linear_strength * 0.5 * cont[t, :, 0] * cont[t, :, 1]\n",
    "                + non_linear_strength * 0.3 * np.sin(cont[t, :, 2])\n",
    "            ).astype(np.float32)\n",
    "        return feat\n",
    "\n",
    "    # init\n",
    "    trend0 = global_mean + float(trend_drift[0])\n",
    "    spatial0 = eigenvalue * float(spatial_weights[0]) * spatial_basis\n",
    "    noise0 = (np.random.randn(N) * noise_std).astype(np.float32)\n",
    "    y[0] = (trend0 + spatial0 + _feat_term(0) + noise0).astype(np.float32)\n",
    "\n",
    "    gate_cnt = 0.0\n",
    "\n",
    "    for t in range(1, n_time_steps):\n",
    "        trend = global_mean + float(trend_drift[t])\n",
    "        spatial = eigenvalue * float(spatial_weights[t]) * spatial_basis\n",
    "        noise = (np.random.randn(N) * noise_std).astype(np.float32)\n",
    "\n",
    "        prev = y[t - 1]\n",
    "        w0 = max(0, t - nar_scale_window)\n",
    "\n",
    "        # rolling scale + rolling mean (Version 2)\n",
    "        mu = float(np.mean(y[w0:t]))                       # rolling mean over window\n",
    "        scale = float(np.std(y[w0:t]) + eps)               # rolling std over window\n",
    "        z_global = float((np.mean(prev) - mu) / scale)     # centered global gate signal\n",
    "\n",
    "        gate = 1.0 if (z_global > gate_threshold) else 0.0\n",
    "        gate_cnt += gate\n",
    "\n",
    "        rho_eff = y_rho * (gate_low + (gate_high - gate_low) * gate)\n",
    "\n",
    "        rec = (rho_eff * prev + y_gamma * np.tanh(prev / scale)).astype(np.float32)\n",
    "\n",
    "        y[t] = (trend + spatial + _feat_term(t) + rec + noise).astype(np.float32)\n",
    "\n",
    "    if debug_gate_ratio:\n",
    "        gate_ratio = gate_cnt / float(n_time_steps - 1)\n",
    "        print(f\"[Gate {gate_type}] gate_ratio={gate_ratio:.4f} | \"\n",
    "              f\"thr={gate_threshold} | low={gate_low} | high={gate_high} | win={nar_scale_window}\")\n",
    "\n",
    "    cat = np.zeros((n_time_steps, N, 0), dtype=np.int64)\n",
    "    return cat, cont, y\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2) Global settings & dirs\n",
    "# ============================================================\n",
    "GLOBAL_SEED = 42\n",
    "np.random.seed(GLOBAL_SEED)\n",
    "torch.manual_seed(GLOBAL_SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "try:\n",
    "    EXP_ROOT = Path(__file__).resolve().parent\n",
    "except NameError:\n",
    "    EXP_ROOT = Path.cwd()\n",
    "\n",
    "# Scenario table\n",
    "SCENARIOS: Dict[str, Dict[str, float]] = {\n",
    "    \"A\":      {\"noise_std\": 0.3, \"feature_noise_std\": 0.0, \"non_linear_strength\": 0.0, \"eta_rho\": 0.8, \"f_rho\": 0.6},\n",
    "    \"Aprime\": {\"noise_std\": 0.3, \"feature_noise_std\": 0.0, \"non_linear_strength\": 0.0, \"eta_rho\": 0.6, \"f_rho\": 0.6},\n",
    "    \"B\":      {\"noise_std\": 0.5, \"feature_noise_std\": 0.2, \"non_linear_strength\": 1.0, \"eta_rho\": 0.8, \"f_rho\": 0.6},\n",
    "    \"Bprime\": {\"noise_std\": 0.5, \"feature_noise_std\": 0.2, \"non_linear_strength\": 1.0, \"eta_rho\": 0.6, \"f_rho\": 0.6},\n",
    "    \"C\":      {\"noise_std\": 0.5, \"feature_noise_std\": 0.2, \"non_linear_strength\": 2.0, \"eta_rho\": 0.8, \"f_rho\": 0.6},\n",
    "    \"D\":      {\"noise_std\": 0.5, \"feature_noise_std\": 0.2, \"non_linear_strength\": 2.5, \"eta_rho\": 0.4, \"f_rho\": 0.6},\n",
    "    \"E\":      {\"noise_std\": 0.5, \"feature_noise_std\": 0.2, \"non_linear_strength\": 2.5, \"eta_rho\": 0.4, \"f_rho\": 0.8},\n",
    "}\n",
    "\n",
    "# FIX to Scenario C (match your current experiment)\n",
    "SCENARIO_KEY = \"C\"\n",
    "SC = SCENARIOS[SCENARIO_KEY]\n",
    "\n",
    "# NAR params: ONLY 2 GAMMAS\n",
    "Y_RHO = 0.85\n",
    "NAR_SCALE_WINDOW = 50\n",
    "GATE_TYPE = \"A2_global_v2\"\n",
    "GATE_THRESHOLD = 0.0\n",
    "GATE_LOW = 0.5\n",
    "GATE_HIGH = 1.0\n",
    "GAMMA_LIST = [0.10, 0.20]\n",
    "\n",
    "# World size\n",
    "N_POINTS = 36\n",
    "T_TOTAL = 1500\n",
    "EIGENVALUE = 3.0\n",
    "locs = np.linspace(-5.0, 5.0, N_POINTS).astype(np.float32)\n",
    "\n",
    "# Split\n",
    "train_ratio = 0.70\n",
    "val_ratio = 0.15\n",
    "\n",
    "# TFT hyperparams\n",
    "L, H = 56, 24\n",
    "INTERNAL_VAL_STEPS = 240\n",
    "\n",
    "N_EPOCHS = 30\n",
    "HIDDEN_SIZE = 64\n",
    "N_HEADS = 4\n",
    "DROPOUT = 0.1\n",
    "BATCH_SIZE = 32\n",
    "LR = 3e-4\n",
    "\n",
    "# Time index\n",
    "time_start = pd.Timestamp(\"2000-01-01 00:00:00\")\n",
    "time_index = pd.date_range(start=time_start, periods=T_TOTAL, freq=\"1H\")\n",
    "freq = \"1H\"\n",
    "\n",
    "PAST_COV_COLS = [\"f1\", \"f2\", \"f3\"]\n",
    "\n",
    "# output dirs\n",
    "ROOT_TAG = f\"synth_tft_{SCENARIO_KEY}_NAR_{GATE_TYPE}_yrho{Y_RHO}_win{NAR_SCALE_WINDOW}_1D_NOSTATIC_ONLY2G\"\n",
    "CKPT_DIR = (EXP_ROOT / f\"darts_ckpt_{ROOT_TAG}\").resolve()\n",
    "RUNS_DIR = (EXP_ROOT / f\"TFT_runs_{ROOT_TAG}\").resolve()\n",
    "PLOTS_DIR = (EXP_ROOT / f\"TFT_plots_{ROOT_TAG}_2figs\").resolve()\n",
    "RESULTS_DIR = (EXP_ROOT / f\"TFT_results_{ROOT_TAG}\").resolve()\n",
    "\n",
    "for d in [CKPT_DIR, RUNS_DIR, PLOTS_DIR, RESULTS_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SUMMARY_ROWS: List[Dict[str, Any]] = []\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3) Loop only two gammas\n",
    "# ============================================================\n",
    "for Y_GAMMA in GAMMA_LIST:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"RUN TFT | SCENARIO={SCENARIO_KEY} | y_rho={Y_RHO} | win={NAR_SCALE_WINDOW} | y_gamma={Y_GAMMA}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    EXP_TAG = f\"{ROOT_TAG}_ygamma{Y_GAMMA}\"\n",
    "\n",
    "    # per-gamma dirs\n",
    "    ckpt_dir = (CKPT_DIR / f\"ygamma_{Y_GAMMA}\").resolve()\n",
    "    runs_dir = (RUNS_DIR / f\"ygamma_{Y_GAMMA}\").resolve()\n",
    "    plots_dir = (PLOTS_DIR / f\"ygamma_{Y_GAMMA}\").resolve()\n",
    "    for d in [ckpt_dir, runs_dir, plots_dir]:\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # ============================================================\n",
    "    # 3.1) Generate synthetic data (NAR, EXACTLY SAME AS OLS)\n",
    "    # ============================================================\n",
    "    print(\"\\n=== Scenario settings ===\")\n",
    "    print(\"Scenario:\", SCENARIO_KEY)\n",
    "    print(SC)\n",
    "    print(\"NAR params:\", {\"y_rho\": Y_RHO, \"y_gamma\": Y_GAMMA, \"nar_scale_window\": NAR_SCALE_WINDOW, \"gate_type\": GATE_TYPE})\n",
    "\n",
    "    cat_synth, cont_synth, y_synth = generate_time_NAR_synthetic_data(\n",
    "        locs=locs,\n",
    "        n_time_steps=T_TOTAL,\n",
    "        noise_std=SC[\"noise_std\"],\n",
    "        eigenvalue=EIGENVALUE,\n",
    "        eta_rho=SC[\"eta_rho\"],\n",
    "        f_rho=SC[\"f_rho\"],\n",
    "        global_mean=50.0,\n",
    "        feature_noise_std=SC[\"feature_noise_std\"],\n",
    "        non_linear_strength=SC[\"non_linear_strength\"],\n",
    "        seed=GLOBAL_SEED,\n",
    "        y_rho=float(Y_RHO),\n",
    "        y_gamma=float(Y_GAMMA),\n",
    "        nar_scale_window=int(NAR_SCALE_WINDOW),\n",
    "        gate_type=GATE_TYPE,\n",
    "        gate_threshold=float(GATE_THRESHOLD),\n",
    "        gate_low=float(GATE_LOW),\n",
    "        gate_high=float(GATE_HIGH),\n",
    "        debug_gate_ratio=True,\n",
    "    )\n",
    "\n",
    "    # ---- HARD identity check (compare with OLS side) ----\n",
    "    y_md5 = hashlib.md5(y_synth.tobytes()).hexdigest()\n",
    "    print(\"Synthetic y shape:\", y_synth.shape)\n",
    "    print(\"Synthetic cont shape:\", cont_synth.shape)\n",
    "    print(\"y stats (unscaled) mean/std/mean|y|:\",\n",
    "          float(y_synth.mean()), float(y_synth.std()), float(np.mean(np.abs(y_synth))))\n",
    "    print(\"y_md5:\", y_md5)\n",
    "\n",
    "    Y = y_synth.astype(np.float32)     # (T, N)\n",
    "    X = cont_synth.astype(np.float32)  # (T, N, 3)\n",
    "    T_total, N = Y.shape\n",
    "\n",
    "    # dummy categorical features (for prepare_all_with_scaling interface)\n",
    "    cat_dummy = np.zeros((T_total, N, 1), dtype=np.int64)\n",
    "\n",
    "    # ============================================================\n",
    "    # 3.2) Train/Val/Test split + pooled scaling (train-only)\n",
    "    # ============================================================\n",
    "    cut_train = int(T_total * train_ratio)\n",
    "    cut_val = int(T_total * (train_ratio + val_ratio))\n",
    "    if not (0 < cut_train < cut_val < T_total):\n",
    "        raise ValueError(\"Bad split indices computed from ratios.\")\n",
    "\n",
    "    print(\"\\n=== Split (by time index) ===\")\n",
    "    print(\"Train:\", 0, \"->\", cut_train - 1, \"| len =\", cut_train)\n",
    "    print(\"Val  :\", cut_train, \"->\", cut_val - 1, \"| len =\", cut_val - cut_train)\n",
    "    print(\"Test :\", cut_val, \"->\", T_total - 1, \"| len =\", T_total - cut_val)\n",
    "\n",
    "    train_ds, val_ds, test_ds, preprocessor = prepare_all_with_scaling(\n",
    "        cat_features=cat_dummy,\n",
    "        cont_features=X,\n",
    "        targets=Y,\n",
    "        train_ratio=train_ratio,\n",
    "        val_ratio=val_ratio,\n",
    "        feature_scaler_type=\"standard\",\n",
    "        target_scaler_type=\"standard\",\n",
    "        fit_on_train_only=True,\n",
    "    )\n",
    "\n",
    "    def stitch_targets(dsets) -> np.ndarray:\n",
    "        return np.concatenate([ds.tensors[2].detach().cpu().numpy().astype(np.float32) for ds in dsets], axis=0)\n",
    "\n",
    "    def stitch_cont_features(dsets) -> np.ndarray:\n",
    "        return np.concatenate([ds.tensors[1].detach().cpu().numpy().astype(np.float32) for ds in dsets], axis=0)\n",
    "\n",
    "    Y_scaled = stitch_targets([train_ds, val_ds, test_ds])        # (T, N)\n",
    "    X_scaled = stitch_cont_features([train_ds, val_ds, test_ds])  # (T, N, 3)\n",
    "\n",
    "    print(\"\\n=== After pooled scaling (train-only) ===\")\n",
    "    print(\"Y_scaled:\", Y_scaled.shape, \"| finite:\", bool(np.isfinite(Y_scaled).all()))\n",
    "    print(\"X_scaled:\", X_scaled.shape, \"| finite:\", bool(np.isfinite(X_scaled).all()))\n",
    "\n",
    "    # ============================================================\n",
    "    # 3.3) Build TimeSeries lists (target + past cov). NO static cov.\n",
    "    # ============================================================\n",
    "    series_all: List[TimeSeries] = []\n",
    "    pcov_all: List[TimeSeries] = []\n",
    "\n",
    "    for j in range(N):\n",
    "        name = f\"grid_{j:03d}\"\n",
    "\n",
    "        ts = TimeSeries.from_times_and_values(\n",
    "            times=time_index,\n",
    "            values=Y_scaled[:, j:j + 1].astype(np.float32),\n",
    "            columns=[name],\n",
    "            freq=freq,\n",
    "        )\n",
    "        series_all.append(ts)\n",
    "\n",
    "        pc = TimeSeries.from_times_and_values(\n",
    "            times=time_index,\n",
    "            values=X_scaled[:, j, :].astype(np.float32),\n",
    "            columns=[f\"{name}_{c}\" for c in PAST_COV_COLS],\n",
    "            freq=freq,\n",
    "        )\n",
    "        pcov_all.append(pc)\n",
    "\n",
    "    # ============================================================\n",
    "    # 3.4) Internal validation (tail of train) for early stopping\n",
    "    # ============================================================\n",
    "    def slice_list(xs, a, b):\n",
    "        return [x[a:b] for x in xs]\n",
    "\n",
    "    train_series = slice_list(series_all, 0, cut_train)\n",
    "    train_pcov = slice_list(pcov_all, 0, cut_train)\n",
    "\n",
    "    iv_start = max(0, cut_train - INTERNAL_VAL_STEPS)\n",
    "    iv_end = cut_train\n",
    "    min_needed = L + H\n",
    "    if (iv_end - iv_start) < min_needed:\n",
    "        iv_start = max(0, iv_end - min_needed)\n",
    "\n",
    "    val_series = slice_list(series_all, iv_start, iv_end)\n",
    "    val_pcov = slice_list(pcov_all, iv_start, iv_end)\n",
    "\n",
    "    print(\"\\n=== INTERNAL validation (for early stopping only) ===\")\n",
    "    print(\"Train len:\", len(train_series[0]))\n",
    "    print(\"IntVal idx:\", iv_start, \"->\", iv_end - 1, \"| len =\", len(val_series[0]))\n",
    "    print(\"IntVal time:\", time_index[iv_start], \"->\", time_index[iv_end - 1])\n",
    "\n",
    "    # ============================================================\n",
    "    # 3.5) Train TFT\n",
    "    # ============================================================\n",
    "    MODEL_NAME = f\"tft_{EXP_TAG}_L{L}_H{H}_seed{GLOBAL_SEED}\"\n",
    "\n",
    "    tft = TFTModel(\n",
    "        input_chunk_length=L,\n",
    "        output_chunk_length=H,\n",
    "        n_epochs=N_EPOCHS,\n",
    "        hidden_size=HIDDEN_SIZE,\n",
    "        num_attention_heads=N_HEADS,\n",
    "        dropout=DROPOUT,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        optimizer_kwargs={\"lr\": LR},\n",
    "        add_relative_index=True,\n",
    "        random_state=GLOBAL_SEED,\n",
    "        force_reset=True,\n",
    "        model_name=MODEL_NAME,\n",
    "        work_dir=str(ckpt_dir),\n",
    "        save_checkpoints=True,\n",
    "        pl_trainer_kwargs={\n",
    "            \"accelerator\": \"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "            \"devices\": 1,\n",
    "            \"enable_progress_bar\": True,\n",
    "            \"enable_model_summary\": False,\n",
    "            \"enable_checkpointing\": True,\n",
    "            \"callbacks\": [EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=6)],\n",
    "            \"logger\": CSVLogger(save_dir=str(runs_dir), name=MODEL_NAME),\n",
    "            \"gradient_clip_val\": 1.0,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    print(f\"\\n=== Training TFT ({SCENARIO_KEY}, NAR A2_global_v2, 1D locs, NO static) | y_gamma={Y_GAMMA} ===\")\n",
    "    tft.fit(\n",
    "        series=train_series,\n",
    "        past_covariates=train_pcov,\n",
    "        val_series=val_series,\n",
    "        val_past_covariates=val_pcov,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== Loading best checkpoint ===\")\n",
    "    tft = TFTModel.load_from_checkpoint(model_name=MODEL_NAME, work_dir=str(ckpt_dir), best=True)\n",
    "    print(\"Loaded best checkpoint.\")\n",
    "\n",
    "    # ============================================================\n",
    "    # 3.6) Rolling non-overlap over TEST (step=H)\n",
    "    # ============================================================\n",
    "    test_start = cut_val\n",
    "    start_ctx = max(test_start, L)\n",
    "\n",
    "    yhat_roll, ytrue_roll, t0_list = rolling_nonoverlap(\n",
    "        tft, series_all, pcov_all, start_ctx, T_total, L, H\n",
    "    )\n",
    "\n",
    "    W = yhat_roll.shape[0]\n",
    "    print(\"\\n=== Rolling non-overlap (POOLED, TEST) ===\")\n",
    "    print(f\"windows={W} | step={H} | each window predicts H={H} | points={N}\")\n",
    "\n",
    "    diff = yhat_roll - ytrue_roll\n",
    "    rmse = float(np.sqrt(np.mean(diff ** 2)))\n",
    "    mae = float(np.mean(np.abs(diff)))\n",
    "    print(\"RMSE:\", rmse)\n",
    "    print(\"MAE :\", mae)\n",
    "\n",
    "    # q-risk\n",
    "    yhat_f = yhat_roll.reshape(-1, N)\n",
    "    ytrue_f = ytrue_roll.reshape(-1, N)\n",
    "\n",
    "    print(\"\\n=== P50 q-risk (ROLLING, TEST) ===\")\n",
    "    qr_scaled = qrisk(ytrue_f, yhat_f)\n",
    "    print(\"scaled  :\", qr_scaled)\n",
    "\n",
    "    ytrue_un = preprocessor.inverse_transform_targets(ytrue_f)\n",
    "    yhat_un = preprocessor.inverse_transform_targets(yhat_f)\n",
    "    qr_unscaled = qrisk(ytrue_un, yhat_un)\n",
    "    print(\"unscaled:\", qr_unscaled)\n",
    "\n",
    "    # ============================================================\n",
    "    # 3.7) Plot: 2 figs per grid point\n",
    "    # ============================================================\n",
    "    w0 = 0\n",
    "    t0_first = t0_list[w0]\n",
    "\n",
    "    print(f\"\\n=== Plotting 2 figs per grid point | y_gamma={Y_GAMMA} ===\")\n",
    "    plot_two_figs_all_points(\n",
    "        plots_dir,\n",
    "        exp_tag=EXP_TAG,\n",
    "        scenario_key=SCENARIO_KEY,\n",
    "        N=N,\n",
    "        H=H,\n",
    "        w0=w0,\n",
    "        t0_first=t0_first,\n",
    "        time_index=time_index,\n",
    "        test_start=test_start,\n",
    "        test_end=T_total,\n",
    "        ytrue_roll=ytrue_roll,\n",
    "        yhat_roll=yhat_roll,\n",
    "        Y_scaled=Y_scaled,\n",
    "        t0_list=t0_list,\n",
    "    )\n",
    "\n",
    "    # ============================================================\n",
    "    # 3.8) Save per-gamma row\n",
    "    # ============================================================\n",
    "    row = {\n",
    "        \"scenario\": SCENARIO_KEY,\n",
    "        \"noise_std\": float(SC[\"noise_std\"]),\n",
    "        \"feature_noise_std\": float(SC[\"feature_noise_std\"]),\n",
    "        \"non_linear_strength\": float(SC[\"non_linear_strength\"]),\n",
    "        \"eta_rho\": float(SC[\"eta_rho\"]),\n",
    "        \"f_rho\": float(SC[\"f_rho\"]),\n",
    "        \"y_rho\": float(Y_RHO),\n",
    "        \"y_gamma\": float(Y_GAMMA),\n",
    "        \"nar_scale_window\": int(NAR_SCALE_WINDOW),\n",
    "        \"gate_type\": GATE_TYPE,\n",
    "        \"gate_threshold\": float(GATE_THRESHOLD),\n",
    "        \"gate_low\": float(GATE_LOW),\n",
    "        \"gate_high\": float(GATE_HIGH),\n",
    "        \"y_md5\": y_md5,\n",
    "        \"rmse_scaled\": rmse,\n",
    "        \"mae_scaled\": mae,\n",
    "        \"qrisk_p50_scaled\": qr_scaled,\n",
    "        \"qrisk_p50_unscaled\": qr_unscaled,\n",
    "        \"windows\": int(W),\n",
    "        \"L\": int(L),\n",
    "        \"H\": int(H),\n",
    "        \"T_total\": int(T_TOTAL),\n",
    "        \"N_points\": int(N_POINTS),\n",
    "        \"eigenvalue\": float(EIGENVALUE),\n",
    "        \"global_seed\": int(GLOBAL_SEED),\n",
    "        \"exp_tag\": EXP_TAG,\n",
    "        \"plots_dir\": str(plots_dir),\n",
    "        \"ckpt_dir\": str(ckpt_dir),\n",
    "    }\n",
    "    SUMMARY_ROWS.append(row)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4) Save summary CSV (2 rows)\n",
    "# ============================================================\n",
    "summary_df = pd.DataFrame(SUMMARY_ROWS)\n",
    "out_csv = (RESULTS_DIR / \"TFT_C_y0p85_w50_g0p1_0p2_A2v2.csv\").resolve()\n",
    "summary_df.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DONE. Saved TFT summary (2 rows) to:\")\n",
    "print(out_csv)\n",
    "print(\"=\" * 80)\n",
    "print(summary_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial-neural-adapter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
